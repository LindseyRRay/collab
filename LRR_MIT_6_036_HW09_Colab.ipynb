{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LRR MIT 6.036 HW09 Colab",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lrraymond13/collab/blob/master/LRR_MIT_6_036_HW09_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "wCZ5V-cO65Yr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#MIT 6.036 Spring 2019: Homework 9#\n",
        "\n",
        "This colab notebook provides code and a framework for question 1 and 5 of the [the homework](https://lms.mitx.mit.edu/courses/course-v1:MITx+6.036+2019_Spring/courseware/Week9/week9_homework).  You can work out your solutions here, then submit your results back on the homework page when ready.\n"
      ]
    },
    {
      "metadata": {
        "id": "oqYqLxGp7hZZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ]
    },
    {
      "metadata": {
        "id": "NaNYfsS87tUi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, download the code distribution for this homework that contains test cases and helper functions.\n",
        "\n",
        "Run the next code block to download and import the code for this lab."
      ]
    },
    {
      "metadata": {
        "id": "c7CRuXxj7ubB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "4269e635-8b85-4d80-83dd-689ebc66593f"
      },
      "cell_type": "code",
      "source": [
        "!rm -rf code_for_hw9*\n",
        "!wget --quiet https://introml.odl.mit.edu/cat-soop/_static/6.036/homework/hw09/code_for_hw9.zip\n",
        "!unzip code_for_hw9.zip\n",
        "!mv code_for_hw9/* .\n",
        "\n",
        "from dist import *\n",
        "from sm import *\n",
        "from util import *\n",
        "from mdp import *\n",
        "\n",
        "import mdp\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  code_for_hw9.zip\n",
            "   creating: code_for_hw9/\n",
            "  inflating: code_for_hw9/util.py    \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/code_for_hw9/\n",
            "  inflating: __MACOSX/code_for_hw9/._util.py  \n",
            "  inflating: code_for_hw9/sm.py      \n",
            "  inflating: __MACOSX/code_for_hw9/._sm.py  \n",
            "  inflating: code_for_hw9/mdp.py     \n",
            "  inflating: __MACOSX/code_for_hw9/._mdp.py  \n",
            "  inflating: code_for_hw9/tests.py   \n",
            "  inflating: __MACOSX/code_for_hw9/._tests.py  \n",
            "  inflating: code_for_hw9/dist.py    \n",
            "  inflating: __MACOSX/code_for_hw9/._dist.py  \n",
            "  inflating: __MACOSX/._code_for_hw9  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uhGY4b888N52",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1) State Machines\n",
        "\n",
        "We will implement state machines as sub-classes of the `SM` class, which specifies the `start_state`, `transition_fn` and `output_fn`.\n",
        "\n",
        "```\n",
        "class SM:\n",
        "    start_state = None  # default start state\n",
        "    def transition_fn(self, s, i):\n",
        "        '''s:       the current state\n",
        "           i:       the given input\n",
        "           returns: the next state'''\n",
        "        raise NotImplementedError\n",
        "    def output_fn(self, s):\n",
        "        '''s:       the current state\n",
        "           returns: the corresponding output'''\n",
        "        raise NotImplementedError\n",
        "```\n",
        "\n",
        "An example of a sub-class is the `Accumulator` state machine, which adds up (accumulates) its input and outputs the sum. Convince yourself that the implementation works as expected before moving on.\n",
        "\n",
        "```\n",
        "class Accumulator(SM):\n",
        "    start_state = 0\n",
        "    def transition_fn(self, s, i):\n",
        "        return s + i\n",
        "    def output_fn(self, s):\n",
        "        return s\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "sYF-u59B861-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.1 Transduce\n",
        "Implement the `transduce` method for the `SM` class. It is given an input sequence (a list) and returns an output sequence (a list) of the outputs of the state machine on the input sequence. Assume `self.transition_fn` and `self.output_fn` are defined."
      ]
    },
    {
      "metadata": {
        "id": "Xy42nJa69D3i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SM:\n",
        "    start_state = None\n",
        "\n",
        "    def transduce(self, input_seq):\n",
        "        state = self.start_state\n",
        "        output = []\n",
        "        for inp in input_seq:\n",
        "            state = self.transition_fn(state, inp)\n",
        "            output.append(self.output_fn(state))\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kzdkh0p8AGi_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Below is the `Accumulator` state machine implementation that you saw above as well as an unit test to help test your `SM` class."
      ]
    },
    {
      "metadata": {
        "id": "qmRnua5p_U9j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Accumulator(SM):\n",
        "    start_state = 0\n",
        "\n",
        "    def transition_fn(self, s, i):\n",
        "        return s + i\n",
        "\n",
        "    def output_fn(self, s):\n",
        "        return s\n",
        "    \n",
        "def test_accumulator_sm():\n",
        "    res = Accumulator().transduce([-1, 2, 3, -2, 5, 6])\n",
        "    assert(res == [-1, 1, 4, 2, 7, 13])\n",
        "    print(\"Test passed!\")\n",
        "\n",
        "# Unit test\n",
        "test_accumulator_sm()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j-QW8TSk9T1E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.2 Binary Addition\n",
        "Implement a `Binary_Addition` state machine that takes in a sequence of pairs of binary digits (0,1) representing two reversed binary numbers and returns a sequence of digits representing the reversed sum. For instance, to sum two binary numbers `100` and `011`, the input sequence will be `[(0, 1), (0, 1), (1, 0)]`. You will need to define `start_state`, `transition_fn` and `output_fn`. Note that when transduced, the input sequence may need to be extended with an extra (0,0) to output the final carry."
      ]
    },
    {
      "metadata": {
        "id": "JKcWyGrZ9mEj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Binary_Addition(SM):\n",
        "    start_state = (0, 0)\n",
        "\n",
        "    def transition_fn(self, s, x):\n",
        "        (carry, digit) = s\n",
        "        (i0, i1) = x\n",
        "        total = i0 + i1 + carry\n",
        "        return 1 if total > 1 else 0, total % 2\n",
        "\n",
        "    def output_fn(self, s):\n",
        "        (carry, digit) = s\n",
        "        return digit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5hvOZXkcA0Au",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test_binary_addition_sm():\n",
        "    res = Binary_Addition().transduce([(1, 1), (1, 0), (0, 0)])\n",
        "    assert(res == [0, 0, 1])\n",
        "    print(\"Test passed!\")\n",
        "\n",
        "# Unit test\n",
        "test_binary_addition_sm()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vtIAZJN79s0h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.3 Reverser\n",
        "Implement a state machine that reverses a sequence. The input is a list of the form:\n",
        "\n",
        "```\n",
        " sequence1 + ['end'] + sequence2\n",
        " ```\n",
        " \n",
        "`+` refers to concatenation. `sequence1` is a list of strings, the `'end'` string indicates termination, and `sequence2` is arbitrary. The machine reverses `sequence1`: for each entry in the `sequence1`, the machine outputs `None`. For the `'end'` input and each entry in the second sequence, an item from the reversed `sequence1` is output, or `None` if no characters remain."
      ]
    },
    {
      "metadata": {
        "id": "VtsUESbg9wAS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Reverser(SM):\n",
        "    start_state = ([], 'input')\n",
        "\n",
        "    def transition_fn(self, s, x):\n",
        "        (symbols, mode) = s\n",
        "        if x == 'end':\n",
        "            return symbols, 'output'\n",
        "        elif mode == 'input':\n",
        "            return symbols + [x], mode\n",
        "        else:\n",
        "            return symbols[:-1], mode\n",
        "\n",
        "    def output_fn(self, s):\n",
        "        (symbols, mode) = s\n",
        "        if mode == 'output' and len(symbols) > 0:\n",
        "            return symbols[-1]\n",
        "        else:\n",
        "            return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XchT3a-fA9oM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test_reverser_sm():\n",
        "    res = Reverser().transduce(['foo', ' ', 'bar'] + ['end'] + list(range(5)))\n",
        "    assert(res == [None, None, None, 'bar', ' ', 'foo', None, None, None])\n",
        "    print(\"Test passed!\")\n",
        "\n",
        "# Unit test\n",
        "test_reverser_sm()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hmewFWqx_4ep",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.4 RNN\n",
        "An RNN has a transition function and an output function, each of which is defined in terms of weight matrices, offset vectors and activation functions, analogously to standard neural networks.\n",
        "\n",
        "* The inputs $x$ are $l\\times1$ vectors\n",
        "* The states $s$ are $m\\times1$ vectors\n",
        "* The outputs $y$ are $n\\times1$ vectors\n",
        "\n",
        "The behavior is defined as follows:\n",
        "$$\\begin{align*} s_{t} & = f_1(W^{ss} s_{{t-1}} + W^{sx} x_{t} + W^{ss}_0) \\\\ y_{t} & = f_2(W^o s_{t} + W^o_0) \\end{align*}$$\n",
        "\n",
        "where $f_1$ and $f_2$ are two activation functions, such as linear, softmax or tanh.\n",
        "\n",
        "\n",
        "Note that each input `i` below has dimension `l x 1`. Implement the corresponding state machine, where the weights are given in `__init__`. Make sure to set an appropriate `start_state`."
      ]
    },
    {
      "metadata": {
        "id": "TcuRs5y0A4n-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RNN(SM):\n",
        "    def __init__(self, Wsx, Wss, Wo, Wss_0, Wo_0, f1, f2):\n",
        "        self.Wsx = Wsx\n",
        "        self.Wss = Wss\n",
        "        self.Wo = Wo\n",
        "        self.Wss_0 = Wss_0\n",
        "        self.Wo_0 = Wo_0\n",
        "        self.l = self.Wsx.shape[1]\n",
        "        self.m = self.Wss.shape[1]\n",
        "        self.n = self.Wo.shape[1]\n",
        "        self.start_state = np.zeros((self.n, 1))\n",
        "        self.f1 = f1\n",
        "        self.f2 = f2\n",
        "    def transition_fn(self, s, x):\n",
        "        return self.f1(np.dot(self.Wss, s) + np.dot(self.Wsx, x) + self.Wss_0)\n",
        "    def output_fn(self, s):\n",
        "        return self.f2(np.dot(self.Wo, s) + self.Wo_0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DcckX5R1JWII",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def softmax(z):\n",
        "    v = np.exp(z)\n",
        "    return v / np.sum(v, axis = 0)\n",
        "\n",
        "def test_rnn():\n",
        "    Wsx1 = np.array([[0.1],\n",
        "                     [0.3],\n",
        "                     [0.5]])\n",
        "    Wss1 = np.array([[0.1,0.2,0.3],\n",
        "                     [0.4,0.5,0.6],\n",
        "                     [0.7,0.8,0.9]])\n",
        "    Wo1 = np.array([[0.1,0.2,0.3],\n",
        "                    [0.4,0.5,0.6]])\n",
        "    Wss1_0 = np.array([[0.01],\n",
        "                       [0.02],\n",
        "                       [0.03]])\n",
        "    Wo1_0 = np.array([[0.1],\n",
        "                      [0.2]])\n",
        "    in1 = [np.array([[0.1]]),\n",
        "           np.array([[0.3]]),\n",
        "           np.array([[0.5]])]\n",
        "    \n",
        "    rnn = RNN(Wsx1, Wss1, Wo1, Wss1_0, Wo1_0, np.tanh, softmax)\n",
        "    expected = np.array([[[0.4638293846951024], [0.5361706153048975]],\n",
        "                        [[0.4333239107898491], [0.566676089210151]],\n",
        "                        [[0.3821688606165438], [0.6178311393834561]]])\n",
        "\n",
        "    assert(np.allclose(expected, rnn.transduce(in1)))\n",
        "    print(\"Test passed!\")\n",
        "\n",
        "# Unit test\n",
        "test_rnn()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1gRiDImvBrTF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.5 Accumulator Sign RNN\n",
        "Enter the parameter matrices and vectors for an instance of the `RNN` class such that the output is `1` if the cumulative sum of the inputs is positive, `-1` if the cumulative sum is negative and `0` if otherwise. Make sure that you scale the outputs so that the output activation values are very close to `1`, `0` and `-1`. Note that both the inputs and outputs are `1 x 1`.\n",
        "\n",
        "Hint: `np.tanh` may be useful. Remember to convert your Python lists to `np.array`."
      ]
    },
    {
      "metadata": {
        "id": "PhH9pv3GBvam",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Wsx =    np.array([[1]])\n",
        "Wss =    np.array([[1]])\n",
        "Wo =     np.array([[1]])\n",
        "Wss_0 =  np.array([[0]])\n",
        "Wo_0 =   np.array([[0]])\n",
        "f1 =     lambda x: x\n",
        "f2 =     lambda x: np.sign(x)\n",
        "acc_sign = RNN(Wsx, Wss, Wo, Wss_0, Wo_0, f1, f2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "78ug9-PLJk82",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test_acc_sign_rnn(acc_sign_rnn):\n",
        "    res = acc_sign_rnn.transduce([-1, -2, 2, 3, -3, 1])\n",
        "    expected = np.array([[[-1.0]], [[-1.0]], [[-1.0]], [[1.0]], [[-1.0]], [[0.0]]])\n",
        "    assert(np.allclose(expected, res))\n",
        "    print(\"Test passed!\")\n",
        "\n",
        "# Unit test\n",
        "test_acc_sign_rnn(acc_sign)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J01wlpQRCKyo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.6 Autoregression RNN\n",
        "\n",
        "Enter the parameter matrices and vectors for an instance of the `RNN` class such that it implements the following autoregressive model:\n",
        "$$y_t=y_{t-1} - 2y_{t-2} + 3y_{t-3}$$\n",
        "when $x_t = y_{t-1}$. Note that both the inputs and outputs are `1 x 1`.\n"
      ]
    },
    {
      "metadata": {
        "id": "C744ijBCCOm5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Wsx =    np.array([[1], [0], [0]])\n",
        "Wss =    np.array([[0, 0, 0], [1, 0, 0], [0, 1, 0]])\n",
        "Wo =     np.array([[1, -2, 3]])\n",
        "Wss_0 =  np.array([[0], [0], [0]])\n",
        "Wo_0 =   np.array([[0]])\n",
        "f1 =     lambda x: x\n",
        "f2 =     lambda x: x\n",
        "auto = RNN(Wsx, Wss, Wo, Wss_0, Wo_0, f1, f2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4RrDCow1J-M8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test_auto_rnn(auto_rnn):\n",
        "    res = auto_rnn.transduce([np.array([[x]]) for x in range(-2,5)])\n",
        "    expected = np.array([[[-2.0]], [[3.0]], [[-4.0]], [[-2.0]], [[0.0]], [[2.0]], [[4.0]]])\n",
        "    assert(np.allclose(expected, res))\n",
        "    print(\"Test passed!\")\n",
        "    \n",
        "# Unit test\n",
        "test_auto_rnn(auto)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fa8rXc0qDvkh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 5) MDP Implementations\n",
        "\n",
        "We'll be using a couple of simple classes to represent MDPs and probability distributions.\n",
        "\n",
        "###5.1 Working with MDPs\n",
        "\n",
        "Recall that given a $Q_\\pi$ for any policy $\\pi$, then $V_\\pi(s)$ = $\\max_a Q_\\pi(s, a)$.\n",
        "\n",
        "1. Write the `value` method, which takes a $Q$ function (an instance of `TabularQ`) and a state and returns the value `V` of an action that maximizes $Q$ function stored in `q`.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "i9bNukNug53m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def value(q, s):\n",
        "    \"\"\" Return Q*(s,a) based on current Q\n",
        "\n",
        "    >>> q = TabularQ([0,1,2,3],['b','c'])\n",
        "    >>> q.set(0, 'b', 5)\n",
        "    >>> q.set(0, 'c', 10)\n",
        "    >>> q_star = value(q,0)\n",
        "    >>> q_star\n",
        "    10\n",
        "    \"\"\"\n",
        "    return max(q.get(s, a) for a in q.actions)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aUaRY8RtOQv0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test_value():\n",
        "    q = TabularQ([0,1,2,3], ['b','c'])\n",
        "    q.set(0, 'b', 5)\n",
        "    q.set(0, 'c', 10)\n",
        "    assert(value(q, 0) == 10)\n",
        "    print(\"Test passed!\")\n",
        "    \n",
        "test_value()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xAkLsRdMhj5U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "2. Write the `greedy` method, which takes a $Q$ function (an instance of `TabularQ`) and a state and returns the action `a` determined by the policy that acts greedily with respect to the current value of `q`."
      ]
    },
    {
      "metadata": {
        "id": "o-0-YCiVhrq6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def greedy(q, s):\n",
        "    \"\"\" Return pi*(s) based on a greedy strategy.\n",
        "\n",
        "    >>> q = TabularQ([0,1,2,3],['b','c'])\n",
        "    >>> q.set(0, 'b', 5)\n",
        "    >>> q.set(0, 'c', 10)\n",
        "    >>> q.set(1, 'b', 2)\n",
        "    >>> greedy(q, 0)\n",
        "    'c'\n",
        "    >>> greedy(q, 1)\n",
        "    'b'\n",
        "    \"\"\"\n",
        "    # solution is: return argmax(q.actions, lambda a: q.get(s, a))\n",
        "    # Your code here\n",
        "    possible_actions = q.actions\n",
        "    max_v = 0\n",
        "    best_a = None\n",
        "    for a in possible_actions:\n",
        "      if q.get(s,a) >= max_v:\n",
        "        max_v = q.get(s,a)\n",
        "        best_a = a\n",
        "    return best_a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X5SlyiDuOb4n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test_greedy():\n",
        "    q = TabularQ([0, 1, 2, 3],['b', 'c'])\n",
        "    q.set(0, 'b', 5)\n",
        "    q.set(0, 'c', 10)\n",
        "    q.set(1, 'b', 2)\n",
        "    assert(greedy(q, 0) == 'c')\n",
        "    assert(greedy(q, 1) == 'b')\n",
        "    print(\"Test passed!\")\n",
        "\n",
        "test_greedy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EM4maWSahr-F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "3. Write the `epsilon_greedy` method, which takes a state `s` and a parameter `epsilon`, and returns an action. With probability `1 - epsilon` it should select the greedy action and with probability `epsilon` it should select an action uniformly from the set of possible actions.\n",
        "\n",
        "    - You should use `random.random()` to generate a random number to test againts eps.\n",
        "    - You should use the `draw` method of `uniform_dist` to generate a random action.\n",
        "    - You can use the `greedy` function defined earlier."
      ]
    },
    {
      "metadata": {
        "id": "bTNz9DmwiEpJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def epsilon_greedy(q, s, eps = 0.5):\n",
        "    \"\"\" Returns an action.\n",
        "\n",
        "    >>> q = TabularQ([0,1,2,3],['b','c'])\n",
        "    >>> q.set(0, 'b', 5)\n",
        "    >>> q.set(0, 'c', 10)\n",
        "    >>> q.set(1, 'b', 2)\n",
        "    >>> eps = 0.\n",
        "    >>> epsilon_greedy(q, 0, eps) #greedy\n",
        "    'c'\n",
        "    >>> epsilon_greedy(q, 1, eps) #greedy\n",
        "    'b'\n",
        "    \"\"\"\n",
        "    if random.random() < eps:  # True with prob eps, random action\n",
        "        return uniform_dist(q.actions).draw()\n",
        "    else:                   # False with prob 1-eps, greedy action\n",
        "        return greedy(q, s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jXjStECQOqiR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test_epsilon_greedy():\n",
        "    q = TabularQ([0, 1, 2, 3],['b', 'c'])\n",
        "    q.set(0, 'b', 5)\n",
        "    q.set(0, 'c', 10)\n",
        "    q.set(1, 'b', 2)\n",
        "    eps = 0.0\n",
        "    assert(epsilon_greedy(q, 0, eps) == 'c')\n",
        "    assert(epsilon_greedy(q, 1, eps) == 'b')\n",
        "    print(\"Test passed!\")\n",
        "    \n",
        "test_epsilon_greedy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D0FimoqLiJQ_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5.2 Implement Q-Value Iteration\n",
        "Provide the definition of the `value_iteration` function. It takes an MDP instance and a `TabularQ` instance. It should terminate when\n",
        "\n",
        "$$\\max_{(s, a)}\\left|Q_t(s, a) - Q_{t-1}(s, a)\\right| < \\epsilon$$\n",
        "\n",
        "that is, the biggest difference between the value functions on successive iterations is less than input parameter `eps`. This function should return the final `TabularQ` instance. It should do no more that `max_iters` iterations.\n",
        "\n",
        "* Make sure to copy the Q function between iterations, e.g. `new_q = q.copy()`.\n",
        "* The `q` parameter contains the initialization of the Q function.\n",
        "* The `value` function is already defined."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WvvczSHijES5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def value_iteration(mdp, q, eps=0.01, max_iters=1000):\n",
        "    # Your code here\n",
        "    def v(s):\n",
        "        return value(q,s)\n",
        "    for it in range(max_iters):\n",
        "        new_q = q.copy()\n",
        "        delta = 0\n",
        "        for s in mdp.states:\n",
        "            for a in mdp.actions:\n",
        "                new_q.set(s, a, mdp.reward_fn(s, a) + mdp.discount_factor * \\\n",
        "                          mdp.transition_model(s, a).expectation(v))\n",
        "                delta = max(delta, abs(new_q.get(s, a) - q.get(s, a)))\n",
        "        if delta < eps:\n",
        "            return new_q\n",
        "        q = new_q\n",
        "    return q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KBYHRzz-_Q_-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Below is the implementation of the \"tiny\" MDP detailed in Problem 2 and Problem 5.3. We will be using it to test `value_iteration`."
      ]
    },
    {
      "metadata": {
        "id": "pRO8Zf47_Qm0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tiny_reward(s, a):\n",
        "    # Reward function\n",
        "    if s == 1: return 1\n",
        "    elif s == 3: return 2\n",
        "    else: return 0\n",
        "\n",
        "def tiny_transition(s, a):\n",
        "    # Transition function\n",
        "    if s == 0:\n",
        "        if a == 'b':\n",
        "            return DDist({1 : 0.9, 2 : 0.1})\n",
        "        else:\n",
        "            return DDist({1 : 0.1, 2 : 0.9})\n",
        "    elif s == 1:\n",
        "        return DDist({1 : 0.1, 0 : 0.9})\n",
        "    elif s == 2:\n",
        "        return DDist({2 : 0.1, 3 : 0.9})\n",
        "    elif s == 3:\n",
        "        return DDist({3 : 0.1, 0 : 0.9})\n",
        "    \n",
        "def test_value_iteration():\n",
        "    tiny = MDP([0, 1, 2, 3], ['b', 'c'], tiny_transition, tiny_reward, 0.9)\n",
        "    q = TabularQ(tiny.states, tiny.actions)\n",
        "    qvi = value_iteration(tiny, q, eps=0.1, max_iters=100)\n",
        "    expected = dict([((2, 'b'), 5.962924188028282),\n",
        "                     ((1, 'c'), 5.6957634856549095),\n",
        "                     ((1, 'b'), 5.6957634856549095),\n",
        "                     ((0, 'b'), 5.072814297918393),\n",
        "                     ((0, 'c'), 5.262109602844769),\n",
        "                     ((3, 'b'), 6.794664584556008),\n",
        "                     ((3, 'c'), 6.794664584556008),\n",
        "                     ((2, 'c'), 5.962924188028282)])\n",
        "    for k in qvi.q:\n",
        "        assert((qvi.q[k] - expected[k]) < 1.0e-5)\n",
        "    print(\"Test passed!\")\n",
        "\n",
        "test_value_iteration()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mpxPhBqijE6e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5.3 Receding-horizon control and online search\n",
        "Write a procedure `q_em(mdp, s, a, h)` that computes the horizon-h Q value for state `s` and action `a` by using the definition of the finite-horizon Q function in the notes (but including a discount factor). \n",
        "\n",
        "This can be written as a relatively simple recursive procedure with a base case (what is the Q value when horizon is 0?) and a recursive case that computes the horizon `h` values assuming we can (recursively) get horizon `h-1` values."
      ]
    },
    {
      "metadata": {
        "id": "M5qsQ-vVjco9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def q_em_solution(mdp, s, a, h):\n",
        "    if h == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return mdp.reward_fn(s, a) + \\\n",
        "            mdp.discount_factor * \\\n",
        "            sum([p*max([q_em(mdp, sp, ap, h-1) for ap in mdp.actions]) \\\n",
        "                for (sp, p) in mdp.transition_model(s, a).d.items()])\n",
        "      \n",
        "def q_em(mdp, s, a, h):\n",
        "    # Your code here\n",
        "    if h==0:\n",
        "        # recursion base case\n",
        "        return 0\n",
        "    else:\n",
        "        v = mdp.reward_fn(s, a)\n",
        "        d = mdp.discount_factor\n",
        "        ev = 0\n",
        "        for s_prime in mdp.states:\n",
        "            p = mdp.transition_model(\n",
        "                        s, a).prob(s_prime)\n",
        "            ev += p*max(\n",
        "                [q_em(mdp, s_prime, ap, h-1) for ap in mdp.actions])\n",
        "                \n",
        "        return v + d*ev   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7pgEI65qLKKQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will be using the \"tiny\" MDP again to test `q_em`."
      ]
    },
    {
      "metadata": {
        "id": "9i3X0Q_v-3Vo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test_q_em():\n",
        "    tiny = MDP([0, 1, 2, 3], ['b', 'c'], tiny_transition, tiny_reward, 0.9)\n",
        "    assert(np.allclose([q_em(tiny, 0, 'b', 1)], [0.0]))\n",
        "    assert(np.allclose([q_em(tiny, 0, 'b', 2)], [0.81]))\n",
        "    assert(np.allclose([q_em(tiny, 0, 'b', 3)], [1.0287000000000002]))\n",
        "    assert(np.allclose([q_em(tiny, 0, 'c', 3)], [1.4103]))\n",
        "    assert(np.allclose([q_em(tiny, 2, 'b', 3)], [1.9116000000000002]))\n",
        "    print(\"Tests passed!\")\n",
        "\n",
        "test_q_em()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}