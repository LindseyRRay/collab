{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of MIT6.036 hw03 colab notebook","version":"0.3.2","provenance":[{"file_id":"1-Bv9wNU6i8Qtv-oDyzh9Ux5PDvSzDDO5","timestamp":1550843527439},{"file_id":"1kIWGi2TEZ0Agd_qQt1KiD2uZw_5AJFHT","timestamp":1550587496262},{"file_id":"1j2fQR-NQxnazY5MSHqxwlS8z96n8YFMg","timestamp":1549860446001}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"_xIaEwCD406A","colab_type":"text"},"cell_type":"markdown","source":["#MIT 6.036 Spring 2019: Homework 3#\n","\n","This colab notebook provides code and a framework for problems 1-7 of [the homework](https://lms.mitx.mit.edu/courses/course-v1:MITx+6.036+2019_Spring/courseware/Week3/week3_homework/).  You can work out your solutions here, then submit your results back on the homework page when ready.\n","\n","## <section>**Setup**</section>\n","\n","First, download the code distribution for this homework that contains test cases and helper functions.\n","\n","Run the next code block to download and import the code for this lab.\n"]},{"metadata":{"id":"2YM-_zLf9Bp-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":590},"outputId":"9bce3e88-b63c-4e8c-e18d-4e33e35683bd","executionInfo":{"status":"ok","timestamp":1550890458211,"user_tz":300,"elapsed":8791,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["!rm -rf code_and_data_for_hw3*\n","!rm -rf mnist\n","!wget --quiet https://introml.odl.mit.edu/cat-soop/_static/6.036/homework/hw03/code_and_data_for_hw3.zip\n","!unzip code_and_data_for_hw3.zip\n","!mv code_and_data_for_hw3/* .\n","  \n","from code_for_hw3_part1 import *\n","import code_for_hw3_part2 as hw3"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Archive:  code_and_data_for_hw3.zip\n","   creating: code_and_data_for_hw3/__pycache__/\n","  inflating: code_and_data_for_hw3/__pycache__/code_for_hw3_part2.cpython-36.pyc  \n","  inflating: code_and_data_for_hw3/auto-mpg.tsv  \n","  inflating: code_and_data_for_hw3/code_for_hw3_part1.py  \n","  inflating: code_and_data_for_hw3/code_for_hw3_part2.py  \n","  inflating: code_and_data_for_hw3/hw3_part2_main.py  \n","   creating: code_and_data_for_hw3/mnist/\n","  inflating: code_and_data_for_hw3/mnist/mnist_train0.png  \n","  inflating: code_and_data_for_hw3/mnist/mnist_train1.png  \n","  inflating: code_and_data_for_hw3/mnist/mnist_train2.png  \n","  inflating: code_and_data_for_hw3/mnist/mnist_train3.png  \n","  inflating: code_and_data_for_hw3/mnist/mnist_train4.png  \n","  inflating: code_and_data_for_hw3/mnist/mnist_train5.png  \n","  inflating: code_and_data_for_hw3/mnist/mnist_train6.png  \n","  inflating: code_and_data_for_hw3/mnist/mnist_train7.png  \n","  inflating: code_and_data_for_hw3/mnist/mnist_train8.png  \n","  inflating: code_and_data_for_hw3/mnist/mnist_train9.png  \n","  inflating: code_and_data_for_hw3/reviews.tsv  \n","  inflating: code_and_data_for_hw3/stopwords.txt  \n","Importing code_for_hw03\n","Imported tidy_plot, plot_separator, plot_data, plot_nonlin_sep, cv, rv, y, positive, score\n","Datasets: super_simple_separable_through_origin(), super_simple_separable(), xor(), xor_more()\n","Tests for part 2: test_linear_classifier_with_features, mul, make_polynomial_feature_fun, \n","                  test_with_features\n","Also loaded: perceptron, one_hot_internal, test_one_hot\n","Importing code_for_hw03 (part 2, imported as hw3)\n","Imported tidy_plot, plot_separator, plot_data, plot_nonlin_sep, cv, rv, y, positive, score\n","         xval_learning_alg, eval_classifier\n","Tests: test_linear_classifier\n","Dataset tools: load_auto_data, std_vals, standard, raw, one_hot, auto_data_and_labels\n","               load_review_data, clean, extract_words, bag_of_words, extract_bow_feature_vectors\n","               load_mnist_data, load_mnist_single\n"],"name":"stdout"}]},{"metadata":{"id":"2z1zuhqltjBy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":86},"outputId":"2d2de3e2-f412-45b6-b999-6d5bb937c3a0","executionInfo":{"status":"ok","timestamp":1550843558031,"user_tz":300,"elapsed":399,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["help(tidy_plot)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Help on function tidy_plot in module code_for_hw3_part1:\n","\n","tidy_plot(xmin, xmax, ymin, ymax, center=False, title=None, xlabel=None, ylabel=None)\n","\n"],"name":"stdout"}]},{"metadata":{"id":"xFxhrJ5XDlvb","colab_type":"text"},"cell_type":"markdown","source":["# Feature Transformation"]},{"metadata":{"id":"_bhI4dQB1-UZ","colab_type":"text"},"cell_type":"markdown","source":["## <section>**Running Perceptron**</section>\n","\n","In problems 1,2 and 3, you will have to run the Perceptron algorithm several times to obtain linear classifiers.\n","We provide you with an implementation of the algorithm which you can use to obtain your results.\n","\n","The specifications for the `perceptron`method provided are:\n","* `data` is a numpy array of dimension $d$ by $n$\n","* `labels` is numpy array of dimension $1$ by $n$\n","* `params` is a dictionary specifying extra parameters to this algorithm; your algorithm runs a number of iterations equal to $T$\n","* `hook` is either None or a function that takes the tuple `(th, th0)` as an argument and displays the separator graphically. \n","\n","It should return a tuple of $\\theta$ (a $d$ by 1 array) and $\\theta_0$ (a 1 by 1 array).\n","\n","Note that you are free to modify the method. For example, a useful modification for this homework would be to make the method return the number of mistakes made on the input data, while it runs."]},{"metadata":{"id":"VtYf8ysk-VQU","colab_type":"code","colab":{}},"cell_type":"code","source":["# Perceptron algorithm with offset.\n","# data is dimension d by n\n","# labels is dimension 1 by n\n","# T is a positive integer number of steps to run\n","def perceptron(data, labels, params = {}, hook = None):\n","    # if T not in params, default to 100\n","    T = params.get('T', 100)\n","    (d, n) = data.shape\n","    # add code to count the number of mistakes\n","    mistakes = 0\n","    theta = np.zeros((d, 1))\n","    theta_0 = np.zeros((1, 1))\n","    for t in range(T):\n","        for i in range(n):\n","            x = data[:,i:i+1]\n","            y = labels[:,i:i+1]\n","            if y * positive(x, theta, theta_0) <= 0.0:\n","                mistakes += 1\n","                theta = theta + y * x\n","                theta_0 = theta_0 + y\n","                if hook: hook((theta, theta_0))\n","    print('Total mistakes , ', mistakes)\n","    return theta, theta_0\n","  \n","\n","def eval_classifier(learner, data_train, labels_train, data_test, labels_test):\n","    th, th0 = learner(data_train, labels_train)\n","    return score(data_test, labels_test, th, th0)/data_test.shape[1]\n","\n","def positive(x, th, th0):\n","    return np.sign(th.T@x + th0)\n","\n","def score(data, labels, th, th0):\n","    return np.sum(positive(data, th, th0) == labels)\n","\n","def xval_learning_alg(learner, data, labels, k):\n","    s_data = np.array_split(data, k, axis=1)\n","    s_labels = np.array_split(labels, k, axis=1)\n","\n","    score_sum = 0\n","    idx = np.arange(n)\n","    np.random.seed(0)\n","    np.random.shuffle(idx)\n","    for i in range(k):\n","        data_train = np.concatenate(s_data[:i] + s_data[i+1:], axis=1)\n","        labels_train = np.concatenate(s_labels[:i] + s_labels[i+1:], axis=1)\n","        data_test = np.array(s_data[i])\n","        labels_test = np.array(s_labels[i])\n","        score_sum += eval_classifier(learner, data_train, labels_train,\n","                                              data_test, labels_test)\n","    return score_sum/k"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OXbaj4AHfomD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"b7574462-fa1a-4fca-fd0a-b63206e378aa","executionInfo":{"status":"ok","timestamp":1550844047815,"user_tz":300,"elapsed":481,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["import math\n","print(.3/math.sqrt(5/4))\n","print((math.pow(800, 2) + math.pow(.8, 2) + 1)/(math.pow(.268, 2)))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["0.2683281572999747\n","8910693.361550456\n"],"name":"stdout"}]},{"metadata":{"id":"L3Cb7Y0Qg_eC","colab_type":"code","colab":{}},"cell_type":"code","source":["data = np.array([[200, 800, 200, 800],\n","             [0.2,  0.2,  0.8,  0.8],\n","               [1, 1, 1, 1]])\n","labels = np.array([[-1, -1, 1, 1]])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7SKYAFlwhTMp","colab_type":"code","colab":{}},"cell_type":"code","source":["def perceptron_origin(data, labels, params = {}, hook = None):\n","    # if T not in params, default to 100\n","    T = params.get('T', 100)\n","    (d, n) = data.shape\n","    # add code to count the number of mistakes\n","    mistakes = 0\n","    theta = np.zeros((d, 1))\n","    for t in range(T):\n","        data_mistakes = 0\n","        for i in range(n):\n","            x = data[:,i:i+1]\n","            y = labels[:,i:i+1]\n","            if y*np.dot(theta.T, x) <= 0.0:\n","                mistakes += 1\n","                data_mistakes += 1\n","                theta = theta + y * x\n","                if hook: hook((theta, theta_0))\n","        #print('mistakes ', mistakes)\n","        if data_mistakes == 0:\n","          print('Total mistakes , ', mistakes)\n","          print('returning early')\n","          return theta\n","    print('Total mistakes , ', mistakes)\n","    return theta"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ntiHaVtLhI1m","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"outputId":"3c983752-a1d8-4973-e6ca-dbdd2aae6311","executionInfo":{"status":"ok","timestamp":1550844915185,"user_tz":300,"elapsed":5763,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["# test the perceptron\n","perceptron_origin(data, labels, params={'T': 1000000})"],"execution_count":49,"outputs":[{"output_type":"stream","text":["Total mistakes ,  666696\n","returning early\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array([[-2.000000e+02],\n","       [ 2.000068e+05],\n","       [-4.000000e+00]])"]},"metadata":{"tags":[]},"execution_count":49}]},{"metadata":{"id":"UOii7F8zkLDw","colab_type":"code","colab":{}},"cell_type":"code","source":["data = np.array([[.200, .800, .200, .800],\n","             [0.2,  0.2,  0.8,  0.8],\n","               [1, 1, 1, 1]])\n","labels = np.array([[-1, -1, 1, 1]])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"f1mQaK7Ilcqp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"outputId":"7048aa88-fe86-4fe5-a41f-6a1f0f8b2cf3","executionInfo":{"status":"ok","timestamp":1550845994483,"user_tz":300,"elapsed":422,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["perceptron_origin(data, labels, params={'T': 1000})"],"execution_count":57,"outputs":[{"output_type":"stream","text":["Total mistakes ,  7\n","returning early\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array([[-0.2],\n","       [ 1.6],\n","       [-1. ]])"]},"metadata":{"tags":[]},"execution_count":57}]},{"metadata":{"id":"ZzqUR755Joij","colab_type":"text"},"cell_type":"markdown","source":["## <section>2D) Encoding Discrete Values</section>\n","\n","It is common to encode sets of discrete values, for machine learning, not as a single multi-valued feature, but using a one hot encoding. So, if there are $k$ values in the discrete set, we would transform that single multi-valued feature into $k$ binary-valued features, in which feature $i$ has value $+1$ if the original feature value was $i$ and has value $0$ (or $-1$) otherwise.\n","\n","Write a function `one_hot` that takes as input $x$, a single feature value (between $1$ and $k$), and $k$, the total possible number of values this feature can take on, and transform it to a numpy column vector of $k$ binary features using a one-hot encoding (remember vectors have zero-based indexing)."]},{"metadata":{"id":"cTmSSfUBorrr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"f6a9dc9c-48f2-43ea-c9dd-a9e52864f26b","executionInfo":{"status":"ok","timestamp":1550846962571,"user_tz":300,"elapsed":333,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["data =   np.array([[2, 3,  4,  5]])\n","labels = np.array([[1, 1, -1, -1]])\n","\n","perceptron(data, labels)"],"execution_count":70,"outputs":[{"output_type":"stream","text":["Total mistakes ,  29\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(array([[-2.]]), array([[7.]]))"]},"metadata":{"tags":[]},"execution_count":70}]},{"metadata":{"id":"kwHOSJBXqfUW","colab_type":"code","colab":{}},"cell_type":"code","source":["np.zeros()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"R11VPNJ3Jpwb","colab_type":"code","colab":{}},"cell_type":"code","source":["def one_hot(x, k):\n","    # Your implementation here\n","    z = np.zeros(shape=(k,1))\n","    z[x-1,0] = 1\n","    return z"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uOdWFevZJs1U","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"b6e03a09-1079-4c4d-ef40-d3e46b723bfa","executionInfo":{"status":"ok","timestamp":1550846742072,"user_tz":300,"elapsed":565,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["test_one_hot(one_hot)"],"execution_count":64,"outputs":[{"output_type":"stream","text":["Passed! \n","\n"],"name":"stdout"}]},{"metadata":{"id":"-NfB-r1WrFCi","colab_type":"code","colab":{}},"cell_type":"code","source":["# make a one hot for each of the cell phone data points\n","# then run the perceptron\n","data_one_hot = np.concatenate(list(map(lambda x: one_hot(x, 6), data[0, :])), axis=1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JvkQOWS8rhYx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"outputId":"23ad550c-3670-42dd-f1dc-8687857001c0","executionInfo":{"status":"ok","timestamp":1550846974482,"user_tz":300,"elapsed":348,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["data_one_hot"],"execution_count":72,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., 0.],\n","       [1., 0., 0., 0.],\n","       [0., 1., 0., 0.],\n","       [0., 0., 1., 0.],\n","       [0., 0., 0., 1.],\n","       [0., 0., 0., 0.]])"]},"metadata":{"tags":[]},"execution_count":72}]},{"metadata":{"id":"OJK1XURDJuxN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"69742f37-577a-46c7-f90d-2b9b07a6e059","executionInfo":{"status":"ok","timestamp":1550847064659,"user_tz":300,"elapsed":374,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["th, th0 = perceptron(data_one_hot, labels)"],"execution_count":74,"outputs":[{"output_type":"stream","text":["Total mistakes ,  6\n"],"name":"stdout"}]},{"metadata":{"id":"gK3ntPv2sEWQ","colab_type":"code","colab":{}},"cell_type":"code","source":["samsung = one_hot(1, 6)\n","nokia = one_hot(6, 6)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Osu2oHxusNYX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"1093de93-b103-4b6b-d3e0-1acad32cd81e","executionInfo":{"status":"ok","timestamp":1550847150263,"user_tz":300,"elapsed":528,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["print(np.sign(np.dot(th.T, samsung) + th0))\n","print(np.sign(np.dot(th.T, nokia) + th0))"],"execution_count":78,"outputs":[{"output_type":"stream","text":["[[0.]]\n","[[0.]]\n"],"name":"stdout"}]},{"metadata":{"id":"yTV8YHXRsxuY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b3ee54c0-3f57-40a9-c178-6621e4c464ee","executionInfo":{"status":"ok","timestamp":1550847647000,"user_tz":300,"elapsed":366,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["data2 = np.array([[1, 2, 3, 4, 5, 6]])\n","data_one_hot = np.concatenate(list(map(lambda x: one_hot(x, 6), data2[0, :])), axis=1)\n","labels2 = np.array([[1, 1, -1, -1, 1, 1]])\n","\n","th, th0 = perceptron(data_one_hot, labels2)"],"execution_count":81,"outputs":[{"output_type":"stream","text":["Total mistakes ,  8\n"],"name":"stdout"}]},{"metadata":{"id":"78MGREnuuTUg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b543317d-c2b8-4b07-970d-4cd10822a913","executionInfo":{"status":"ok","timestamp":1550847680312,"user_tz":300,"elapsed":320,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["print(th[:,0], th0)"],"execution_count":84,"outputs":[{"output_type":"stream","text":["[ 1.  1. -2. -2.  1.  1.] [[0.]]\n"],"name":"stdout"}]},{"metadata":{"id":"IHCfY1dBJvK3","colab_type":"text"},"cell_type":"markdown","source":["## 3) Polynomial Features\n","\n","One systematic way of generating non-linear transformations of your input features is to consider the polynomials of increasing order.  Given a feature vector $x = [x_1, x_2, ..., x_d]^T$, we can map it into a new feature vector that contains all the factors in a polynomial of order $d$. For example, for $x = [x_1, x_2]^T$ and order 2, we get $$\\phi(x) = [1, x_1, x_2, x_1x_2, x_1^2, x_2^2]^T$$ and for order 3, we get $$\\phi(x) = [1, x_1, x_2, x_1x_2, x_1^2, x_2^2, x_1^2x_2, x_1x_2^2, x_1^3, x_2^3]^T.$$  \n","\n","In the code that has been loaded, we have defined `make_polynomial_feature_fun` that, given the order, returns a feature transformation function (analogous to $\\phi$ in the description).  You should use it in doing this problem."]},{"metadata":{"id":"2MHF3Ej7Jx0r","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"38c8499f-472e-4724-9f48-c53c9a69443a","executionInfo":{"status":"ok","timestamp":1550859791523,"user_tz":300,"elapsed":467,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["## For example, make_polynomial_feature_fun could be used as follows:\n","import numpy as np\n","\n","# Data\n","data = np.zeros((2,1))\n","\n","# Generate transformation of order 2\n","transformation = make_polynomial_feature_fun(50)\n","\n","# Use transformation on data\n","print(len(transformation(data)))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["1326\n"],"name":"stdout"}]},{"metadata":{"id":"VMb41omAdPH4","colab_type":"code","colab":{}},"cell_type":"code","source":["def perceptron(data, labels, params = {}, hook = None):\n","    # if T not in params, default to 100\n","    T = params.get('T', 1000)\n","    (d, n) = data.shape\n","    # add code to count the number of mistakes\n","    mistakes = 0\n","    theta = np.zeros((d, 1))\n","    theta_0 = np.zeros((1, 1))\n","    for t in range(T):\n","        iter_mistakes = 0\n","        for i in range(n):\n","            x = data[:,i:i+1]\n","            y = labels[:,i:i+1]\n","            if y * positive(x, theta, theta_0) <= 0.0:\n","                mistakes += 1\n","                theta = theta + y * x\n","                theta_0 = theta_0 + y\n","                if hook: hook((theta, theta_0))\n","        if iter_mistakes == 0:\n","          print('finishing early ', mistakes)\n","          return theta, theta_0\n","    print('Total mistakes , ', mistakes)\n","    return theta, theta_0"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Q9lVttgAdffn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":7292},"outputId":"36f619bf-46fb-4f76-a3c9-d4910a00bf1f","executionInfo":{"status":"ok","timestamp":1550863913176,"user_tz":300,"elapsed":32316,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["test_with_features(super_simple_separable_through_origin, order=0, draw=True, pause=False)"],"execution_count":27,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAdkAAAEUCAYAAABnMUxoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFCKyAFCIyAJAIf8NHBmQJXNGCOUAAAAASUVORK5CYII=\n","text/plain":["<Figure size 576x396 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[1.]] th0 [[1.]]\n","th [[0.]] th0 [[0.]]\n","th [[0.]] th0 [[0.]]\n","Final score 0\n","Params [[0.]] [[0.]]\n"],"name":"stdout"}]},{"metadata":{"id":"stwyZryBdzP4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1330},"outputId":"1981001c-47e3-437d-ec62-776ce45cb934","executionInfo":{"status":"ok","timestamp":1550863856186,"user_tz":300,"elapsed":5492,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["test_with_features(super_simple_separable, order=1, draw=True, pause=False)"],"execution_count":26,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAdkAAADsCAYAAAA4h9yoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 576x396 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["th [[1. 2. 5.]] th0 [[1.]]\n","th [[ 0. -1.  3.]] th0 [[0.]]\n","th [[ -1. -13.  -2.]] th0 [[-1.]]\n","th [[  0. -11.   3.]] th0 [[0.]]\n","th [[ 1. -2.  9.]] th0 [[1.]]\n","th [[  0. -14.   4.]] th0 [[0.]]\n","th [[  1. -12.   9.]] th0 [[1.]]\n","th [[ 2. -3. 15.]] th0 [[2.]]\n","th [[  1. -15.  10.]] th0 [[1.]]\n","th [[ 2. -6. 16.]] th0 [[2.]]\n","th [[  1. -18.  11.]] th0 [[1.]]\n","th [[ 2. -9. 17.]] th0 [[2.]]\n","th [[  1. -12.  15.]] th0 [[1.]]\n","th [[ 2. -3. 21.]] th0 [[2.]]\n","th [[  1. -15.  16.]] th0 [[1.]]\n","th [[ 2. -6. 22.]] th0 [[2.]]\n","th [[  1. -18.  17.]] th0 [[1.]]\n","th [[ 2. -9. 23.]] th0 [[2.]]\n","th [[  1. -21.  18.]] th0 [[1.]]\n","th [[  2. -12.  24.]] th0 [[2.]]\n","th [[  1. -15.  22.]] th0 [[1.]]\n","th [[ 2. -6. 28.]] th0 [[2.]]\n","th [[  1. -18.  23.]] th0 [[1.]]\n","th [[ 2. -9. 29.]] th0 [[2.]]\n","th [[  1. -21.  24.]] th0 [[1.]]\n","th [[  2. -12.  30.]] th0 [[2.]]\n","th [[  1. -24.  25.]] th0 [[1.]]\n","th [[  2. -15.  31.]] th0 [[2.]]\n","th [[  1. -18.  29.]] th0 [[1.]]\n","th [[  0. -21.  27.]] th0 [[0.]]\n","th [[  1. -12.  33.]] th0 [[1.]]\n","th [[  0. -24.  28.]] th0 [[0.]]\n","th [[  1. -15.  34.]] th0 [[1.]]\n","th [[  0. -18.  32.]] th0 [[0.]]\n","th [[ -1. -21.  30.]] th0 [[-1.]]\n","th [[  0. -12.  36.]] th0 [[0.]]\n","th [[ -1. -24.  31.]] th0 [[-1.]]\n","th [[  0. -15.  37.]] th0 [[0.]]\n","th [[ -1. -27.  32.]] th0 [[-1.]]\n","th [[  0. -18.  38.]] th0 [[0.]]\n","th [[ -1. -21.  36.]] th0 [[-1.]]\n","th [[ -2. -24.  34.]] th0 [[-2.]]\n","th [[ -1. -15.  40.]] th0 [[-1.]]\n","th [[ -2. -27.  35.]] th0 [[-2.]]\n","th [[ -1. -18.  41.]] th0 [[-1.]]\n","th [[ -2. -21.  39.]] th0 [[-2.]]\n","th [[ -3. -24.  37.]] th0 [[-3.]]\n","th [[ -2. -15.  43.]] th0 [[-2.]]\n","th [[ -3. -27.  38.]] th0 [[-3.]]\n","th [[ -2. -18.  44.]] th0 [[-2.]]\n","th [[ -3. -30.  39.]] th0 [[-3.]]\n","th [[ -2. -21.  45.]] th0 [[-2.]]\n","th [[ -3. -24.  43.]] th0 [[-3.]]\n","th [[ -4. -27.  41.]] th0 [[-4.]]\n","th [[ -3. -18.  47.]] th0 [[-3.]]\n","th [[ -4. -30.  42.]] th0 [[-4.]]\n","th [[ -3. -21.  48.]] th0 [[-3.]]\n","th [[ -4. -24.  46.]] th0 [[-4.]]\n","th [[ -5. -27.  44.]] th0 [[-5.]]\n","th [[ -5. -27.  44.]] th0 [[-5.]]\n","Final score 4\n","Params [[ -5. -27.  44.]] [[-5.]]\n"],"name":"stdout"}]},{"metadata":{"id":"DB1q-fyoeNpF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":7572},"outputId":"e5a8c87a-ae56-4985-8bbb-5cd6f6c0a484","executionInfo":{"status":"ok","timestamp":1550864145797,"user_tz":300,"elapsed":44322,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["test_with_features(xor_more, order=3, draw=True, pause=False)"],"execution_count":31,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAbEAAAFKCAYAAACThWFrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n","text/plain":["<Figure size 576x396 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["th [[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]] th0 [[1.]]\n","th [[ 0.  0. -1.  0. -1. -3.  0. -1. -3. -7.]] th0 [[0.]]\n","th [[ 1.  2.  2.  4.  5.  6.  8. 11. 15. 20.]] th0 [[1.]]\n","th [[ 0.  1. -1.  3.  2. -3.  7.  8.  6. -7.]] th0 [[0.]]\n","th [[ -1.  -2.  -4.  -6.  -7. -12. -20. -19. -21. -34.]] th0 [[-1.]]\n","th [[  0.  -1.  -3.  -5.  -6. -11. -19. -18. -20. -33.]] th0 [[0.]]\n","th [[  1.   1.  -1.  -1.  -2.  -7. -11. -10. -12. -25.]] th0 [[1.]]\n","th [[ 2.  3.  2.  3.  4.  2. -3.  2.  6.  2.]] th0 [[2.]]\n","th [[ 3.  7.  3. 19.  8.  3. 61. 18. 10.  3.]] th0 [[3.]]\n","th [[  2.   6.   0.  18.   5.  -6.  60.  15.   1. -24.]] th0 [[2.]]\n","th [[  1.   3.  -3.   9.  -4. -15.  33. -12. -26. -51.]] th0 [[1.]]\n","th [[  2.   4.  -2.  10.  -3. -14.  34. -11. -25. -50.]] th0 [[2.]]\n","th [[  3.   6.   0.  14.   1. -10.  42.  -3. -17. -42.]] th0 [[3.]]\n","th [[  2.   4.  -1.  10.  -1. -11.  34.  -7. -19. -43.]] th0 [[2.]]\n","th [[  3.   6.   2.  14.   5.  -2.  42.   5.  -1. -16.]] th0 [[3.]]\n","th [[  2.   3.  -1.   5.  -4. -11.  15. -22. -28. -43.]] th0 [[2.]]\n","th [[  3.   4.   0.   6.  -3. -10.  16. -21. -27. -42.]] th0 [[3.]]\n","th [[  4.   6.   2.  10.   1.  -6.  24. -13. -19. -34.]] th0 [[4.]]\n","th [[  3.   4.   1.   6.  -1.  -7.  16. -17. -21. -35.]] th0 [[3.]]\n","th [[ 4.  6.  4. 10.  5.  2. 24. -5. -3. -8.]] th0 [[4.]]\n","th [[  3.   3.   1.   1.  -4.  -7.  -3. -32. -30. -35.]] th0 [[3.]]\n","th [[  4.   4.   2.   2.  -3.  -6.  -2. -31. -29. -34.]] th0 [[4.]]\n","th [[  5.   6.   4.   6.   1.  -2.   6. -23. -21. -26.]] th0 [[5.]]\n","th [[  6.   8.   7.  10.   7.   7.  14. -11.  -3.   1.]] th0 [[6.]]\n","th [[  5.   7.   4.   9.   4.  -2.  13. -14. -12. -26.]] th0 [[5.]]\n","th [[  6.   8.   5.  10.   5.  -1.  14. -13. -11. -25.]] th0 [[6.]]\n","th [[  7.  10.   7.  14.   9.   3.  22.  -5.  -3. -17.]] th0 [[7.]]\n","th [[  6.   8.   6.  10.   7.   2.  14.  -9.  -5. -18.]] th0 [[6.]]\n","th [[ 7. 10.  9. 14. 13. 11. 22.  3. 13.  9.]] th0 [[7.]]\n","th [[  6.   9.   6.  13.  10.   2.  21.   0.   4. -18.]] th0 [[6.]]\n","th [[  5.   6.   3.   4.   1.  -7.  -6. -27. -23. -45.]] th0 [[5.]]\n","th [[  6.   7.   4.   5.   2.  -6.  -5. -26. -22. -44.]] th0 [[6.]]\n","th [[  7.   9.   6.   9.   6.  -2.   3. -18. -14. -36.]] th0 [[7.]]\n","th [[ 8. 11.  9. 13. 12.  7. 11. -6.  4. -9.]] th0 [[8.]]\n","th [[  7.   8.   6.   4.   3.  -2. -16. -33. -23. -36.]] th0 [[7.]]\n","th [[  8.   9.   7.   5.   4.  -1. -15. -32. -22. -35.]] th0 [[8.]]\n","th [[  9.  11.   9.   9.   8.   3.  -7. -24. -14. -27.]] th0 [[9.]]\n","th [[ 10.  13.  12.  13.  14.  12.   1. -12.   4.   0.]] th0 [[10.]]\n","th [[  9.  12.   9.  12.  11.   3.   0. -15.  -5. -27.]] th0 [[9.]]\n","th [[ 10.  14.  11.  16.  15.   7.   8.  -7.   3. -19.]] th0 [[10.]]\n","th [[  9.  12.  10.  12.  13.   6.   0. -11.   1. -20.]] th0 [[9.]]\n","th [[10. 14. 13. 16. 19. 15.  8.  1. 19.  7.]] th0 [[10.]]\n","th [[  9.  13.  10.  15.  16.   6.   7.  -2.  10. -20.]] th0 [[9.]]\n","th [[  8.  10.   7.   6.   7.  -3. -20. -29. -17. -47.]] th0 [[8.]]\n","th [[  9.  11.   8.   7.   8.  -2. -19. -28. -16. -46.]] th0 [[9.]]\n","th [[ 10.  13.  10.  11.  12.   2. -11. -20.  -8. -38.]] th0 [[10.]]\n","th [[ 11.  15.  13.  15.  18.  11.  -3.  -8.  10. -11.]] th0 [[11.]]\n","th [[ 10.  14.  10.  14.  15.   2.  -4. -11.   1. -38.]] th0 [[10.]]\n","th [[ 11.  16.  12.  18.  19.   6.   4.  -3.   9. -30.]] th0 [[11.]]\n","th [[ 10.  14.  11.  14.  17.   5.  -4.  -7.   7. -31.]] th0 [[10.]]\n","th [[11. 16. 14. 18. 23. 14.  4.  5. 25. -4.]] th0 [[11.]]\n","th [[ 10.  15.  11.  17.  20.   5.   3.   2.  16. -31.]] th0 [[10.]]\n","th [[  9.  12.   8.   8.  11.  -4. -24. -25. -11. -58.]] th0 [[9.]]\n","th [[ 10.  13.   9.   9.  12.  -3. -23. -24. -10. -57.]] th0 [[10.]]\n","th [[ 11.  15.  11.  13.  16.   1. -15. -16.  -2. -49.]] th0 [[11.]]\n","th [[ 12.  17.  14.  17.  22.  10.  -7.  -4.  16. -22.]] th0 [[12.]]\n","th [[ 11.  14.  11.   8.  13.   1. -34. -31. -11. -49.]] th0 [[11.]]\n","th [[ 12.  15.  12.   9.  14.   2. -33. -30. -10. -48.]] th0 [[12.]]\n","th [[ 13.  17.  14.  13.  18.   6. -25. -22.  -2. -40.]] th0 [[13.]]\n","th [[ 14.  19.  17.  17.  24.  15. -17. -10.  16. -13.]] th0 [[14.]]\n","th [[ 15.  23.  18.  33.  28.  16.  47.   6.  20. -12.]] th0 [[15.]]\n","th [[ 14.  22.  15.  32.  25.   7.  46.   3.  11. -39.]] th0 [[14.]]\n","th [[ 13.  19.  12.  23.  16.  -2.  19. -24. -16. -66.]] th0 [[13.]]\n","th [[ 14.  21.  14.  27.  20.   2.  27. -16.  -8. -58.]] th0 [[14.]]\n","th [[ 13.  19.  13.  23.  18.   1.  19. -20. -10. -59.]] th0 [[13.]]\n","th [[ 14.  21.  16.  27.  24.  10.  27.  -8.   8. -32.]] th0 [[14.]]\n","th [[ 13.  18.  13.  18.  15.   1.   0. -35. -19. -59.]] th0 [[13.]]\n","th [[ 14.  19.  14.  19.  16.   2.   1. -34. -18. -58.]] th0 [[14.]]\n","th [[ 15.  21.  16.  23.  20.   6.   9. -26. -10. -50.]] th0 [[15.]]\n","th [[ 14.  19.  15.  19.  18.   5.   1. -30. -12. -51.]] th0 [[14.]]\n","th [[ 15.  21.  18.  23.  24.  14.   9. -18.   6. -24.]] th0 [[15.]]\n","th [[ 14.  20.  16.  22.  22.  10.   8. -20.   2. -32.]] th0 [[14.]]\n","th [[ 13.  18.  15.  18.  20.   9.   0. -24.   0. -33.]] th0 [[13.]]\n","th [[ 14.  20.  18.  22.  26.  18.   8. -12.  18.  -6.]] th0 [[14.]]\n","th [[ 13.  19.  15.  21.  23.   9.   7. -15.   9. -33.]] th0 [[13.]]\n","th [[ 12.  17.  14.  17.  21.   8.  -1. -19.   7. -34.]] th0 [[12.]]\n","th [[13. 19. 17. 21. 27. 17.  7. -7. 25. -7.]] th0 [[13.]]\n","th [[ 12.  18.  14.  20.  24.   8.   6. -10.  16. -34.]] th0 [[12.]]\n","th [[ 11.  16.  13.  16.  22.   7.  -2. -14.  14. -35.]] th0 [[11.]]\n","th [[12. 18. 16. 20. 28. 16.  6. -2. 32. -8.]] th0 [[12.]]\n","th [[ 11.  17.  13.  19.  25.   7.   5.  -5.  23. -35.]] th0 [[11.]]\n","th [[ 10.  14.  10.  10.  16.  -2. -22. -32.  -4. -62.]] th0 [[10.]]\n","th [[ 11.  15.  11.  11.  17.  -1. -21. -31.  -3. -61.]] th0 [[11.]]\n","th [[ 12.  17.  13.  15.  21.   3. -13. -23.   5. -53.]] th0 [[12.]]\n","th [[ 13.  19.  16.  19.  27.  12.  -5. -11.  23. -26.]] th0 [[13.]]\n","th [[ 12.  16.  13.  10.  18.   3. -32. -38.  -4. -53.]] th0 [[12.]]\n","th [[ 13.  17.  14.  11.  19.   4. -31. -37.  -3. -52.]] th0 [[13.]]\n","th [[ 14.  19.  16.  15.  23.   8. -23. -29.   5. -44.]] th0 [[14.]]\n","th [[ 15.  21.  19.  19.  29.  17. -15. -17.  23. -17.]] th0 [[15.]]\n","th [[ 16.  25.  20.  35.  33.  18.  49.  -1.  27. -16.]] th0 [[16.]]\n","th [[ 15.  24.  17.  34.  30.   9.  48.  -4.  18. -43.]] th0 [[15.]]\n","th [[ 14.  21.  14.  25.  21.   0.  21. -31.  -9. -70.]] th0 [[14.]]\n","th [[ 15.  23.  16.  29.  25.   4.  29. -23.  -1. -62.]] th0 [[15.]]\n","th [[ 14.  21.  15.  25.  23.   3.  21. -27.  -3. -63.]] th0 [[14.]]\n","th [[ 15.  23.  18.  29.  29.  12.  29. -15.  15. -36.]] th0 [[15.]]\n","th [[ 14.  20.  15.  20.  20.   3.   2. -42. -12. -63.]] th0 [[14.]]\n","th [[ 15.  21.  16.  21.  21.   4.   3. -41. -11. -62.]] th0 [[15.]]\n","th [[ 16.  23.  18.  25.  25.   8.  11. -33.  -3. -54.]] th0 [[16.]]\n","th [[ 15.  21.  17.  21.  23.   7.   3. -37.  -5. -55.]] th0 [[15.]]\n","th [[ 16.  23.  20.  25.  29.  16.  11. -25.  13. -28.]] th0 [[16.]]\n","th [[ 15.  20.  17.  16.  20.   7. -16. -52. -14. -55.]] th0 [[15.]]\n","th [[ 16.  21.  18.  17.  21.   8. -15. -51. -13. -54.]] th0 [[16.]]\n","th [[ 17.  23.  20.  21.  25.  12.  -7. -43.  -5. -46.]] th0 [[17.]]\n","th [[ 18.  25.  23.  25.  31.  21.   1. -31.  13. -19.]] th0 [[18.]]\n","th [[ 17.  24.  21.  24.  29.  17.   0. -33.   9. -27.]] th0 [[17.]]\n","th [[ 16.  22.  20.  20.  27.  16.  -8. -37.   7. -28.]] th0 [[16.]]\n","th [[ 17.  24.  23.  24.  33.  25.   0. -25.  25.  -1.]] th0 [[17.]]\n","th [[ 16.  23.  20.  23.  30.  16.  -1. -28.  16. -28.]] th0 [[16.]]\n","th [[ 15.  22.  18.  22.  28.  12.  -2. -30.  12. -36.]] th0 [[15.]]\n","th [[ 14.  20.  17.  18.  26.  11. -10. -34.  10. -37.]] th0 [[14.]]\n","th [[ 15.  22.  20.  22.  32.  20.  -2. -22.  28. -10.]] th0 [[15.]]\n","th [[ 14.  21.  17.  21.  29.  11.  -3. -25.  19. -37.]] th0 [[14.]]\n","th [[ 15.  23.  19.  25.  33.  15.   5. -17.  27. -29.]] th0 [[15.]]\n","th [[ 14.  22.  17.  24.  31.  11.   4. -19.  23. -37.]] th0 [[14.]]\n","th [[ 13.  20.  16.  20.  29.  10.  -4. -23.  21. -38.]] th0 [[13.]]\n","th [[ 14.  22.  19.  24.  35.  19.   4. -11.  39. -11.]] th0 [[14.]]\n","th [[ 13.  21.  16.  23.  32.  10.   3. -14.  30. -38.]] th0 [[13.]]\n","th [[ 12.  18.  13.  14.  23.   1. -24. -41.   3. -65.]] th0 [[12.]]\n","th [[ 13.  19.  14.  15.  24.   2. -23. -40.   4. -64.]] th0 [[13.]]\n","th [[ 14.  21.  16.  19.  28.   6. -15. -32.  12. -56.]] th0 [[14.]]\n","th [[ 15.  23.  19.  23.  34.  15.  -7. -20.  30. -29.]] th0 [[15.]]\n","th [[ 16.  27.  20.  39.  38.  16.  57.  -4.  34. -28.]] th0 [[16.]]\n","th [[ 15.  26.  17.  38.  35.   7.  56.  -7.  25. -55.]] th0 [[15.]]\n","th [[ 14.  23.  14.  29.  26.  -2.  29. -34.  -2. -82.]] th0 [[14.]]\n","th [[ 15.  25.  16.  33.  30.   2.  37. -26.   6. -74.]] th0 [[15.]]\n","th [[ 14.  23.  15.  29.  28.   1.  29. -30.   4. -75.]] th0 [[14.]]\n","th [[ 15.  25.  18.  33.  34.  10.  37. -18.  22. -48.]] th0 [[15.]]\n","th [[ 14.  22.  15.  24.  25.   1.  10. -45.  -5. -75.]] th0 [[14.]]\n","th [[ 15.  23.  16.  25.  26.   2.  11. -44.  -4. -74.]] th0 [[15.]]\n","th [[ 16.  25.  18.  29.  30.   6.  19. -36.   4. -66.]] th0 [[16.]]\n","th [[ 15.  23.  17.  25.  28.   5.  11. -40.   2. -67.]] th0 [[15.]]\n","th [[ 16.  25.  20.  29.  34.  14.  19. -28.  20. -40.]] th0 [[16.]]\n","th [[ 15.  22.  17.  20.  25.   5.  -8. -55.  -7. -67.]] th0 [[15.]]\n","th [[ 16.  23.  18.  21.  26.   6.  -7. -54.  -6. -66.]] th0 [[16.]]\n","th [[ 17.  25.  20.  25.  30.  10.   1. -46.   2. -58.]] th0 [[17.]]\n","th [[ 16.  23.  19.  21.  28.   9.  -7. -50.   0. -59.]] th0 [[16.]]\n","th [[ 17.  25.  22.  25.  34.  18.   1. -38.  18. -32.]] th0 [[17.]]\n","th [[ 16.  24.  20.  24.  32.  14.   0. -40.  14. -40.]] th0 [[16.]]\n","th [[ 15.  22.  19.  20.  30.  13.  -8. -44.  12. -41.]] th0 [[15.]]\n","th [[ 16.  24.  22.  24.  36.  22.   0. -32.  30. -14.]] th0 [[16.]]\n","th [[ 15.  23.  19.  23.  33.  13.  -1. -35.  21. -41.]] th0 [[15.]]\n","th [[ 16.  25.  21.  27.  37.  17.   7. -27.  29. -33.]] th0 [[16.]]\n","th [[ 15.  24.  19.  26.  35.  13.   6. -29.  25. -41.]] th0 [[15.]]\n","th [[ 14.  22.  18.  22.  33.  12.  -2. -33.  23. -42.]] th0 [[14.]]\n","th [[ 15.  24.  21.  26.  39.  21.   6. -21.  41. -15.]] th0 [[15.]]\n","th [[ 14.  23.  18.  25.  36.  12.   5. -24.  32. -42.]] th0 [[14.]]\n","th [[ 13.  20.  15.  16.  27.   3. -22. -51.   5. -69.]] th0 [[13.]]\n","th [[ 14.  21.  16.  17.  28.   4. -21. -50.   6. -68.]] th0 [[14.]]\n","th [[ 15.  23.  18.  21.  32.   8. -13. -42.  14. -60.]] th0 [[15.]]\n","th [[ 16.  25.  21.  25.  38.  17.  -5. -30.  32. -33.]] th0 [[16.]]\n","th [[ 15.  24.  19.  24.  36.  13.  -6. -32.  28. -41.]] th0 [[15.]]\n","th [[ 14.  22.  18.  20.  34.  12. -14. -36.  26. -42.]] th0 [[14.]]\n","th [[ 15.  24.  21.  24.  40.  21.  -6. -24.  44. -15.]] th0 [[15.]]\n","th [[ 14.  23.  18.  23.  37.  12.  -7. -27.  35. -42.]] th0 [[14.]]\n","th [[ 13.  21.  17.  19.  35.  11. -15. -31.  33. -43.]] th0 [[13.]]\n","th [[ 14.  23.  20.  23.  41.  20.  -7. -19.  51. -16.]] th0 [[14.]]\n","th [[ 13.  22.  17.  22.  38.  11.  -8. -22.  42. -43.]] th0 [[13.]]\n","th [[ 12.  20.  16.  18.  36.  10. -16. -26.  40. -44.]] th0 [[12.]]\n","th [[ 13.  22.  19.  22.  42.  19.  -8. -14.  58. -17.]] th0 [[13.]]\n","th [[ 12.  21.  16.  21.  39.  10.  -9. -17.  49. -44.]] th0 [[12.]]\n","th [[ 11.  18.  13.  12.  30.   1. -36. -44.  22. -71.]] th0 [[11.]]\n","th [[ 12.  19.  14.  13.  31.   2. -35. -43.  23. -70.]] th0 [[12.]]\n","th [[ 13.  21.  16.  17.  35.   6. -27. -35.  31. -62.]] th0 [[13.]]\n","th [[ 14.  23.  19.  21.  41.  15. -19. -23.  49. -35.]] th0 [[14.]]\n","th [[ 15.  27.  20.  37.  45.  16.  45.  -7.  53. -34.]] th0 [[15.]]\n","th [[ 14.  26.  17.  36.  42.   7.  44. -10.  44. -61.]] th0 [[14.]]\n","th [[ 13.  23.  14.  27.  33.  -2.  17. -37.  17. -88.]] th0 [[13.]]\n","th [[ 14.  25.  16.  31.  37.   2.  25. -29.  25. -80.]] th0 [[14.]]\n","th [[ 13.  23.  15.  27.  35.   1.  17. -33.  23. -81.]] th0 [[13.]]\n","th [[ 14.  25.  18.  31.  41.  10.  25. -21.  41. -54.]] th0 [[14.]]\n","th [[ 13.  22.  15.  22.  32.   1.  -2. -48.  14. -81.]] th0 [[13.]]\n","th [[ 14.  24.  17.  26.  36.   5.   6. -40.  22. -73.]] th0 [[14.]]\n","th [[ 13.  22.  16.  22.  34.   4.  -2. -44.  20. -74.]] th0 [[13.]]\n","th [[ 14.  24.  19.  26.  40.  13.   6. -32.  38. -47.]] th0 [[14.]]\n","th [[ 13.  22.  18.  22.  38.  12.  -2. -36.  36. -48.]] th0 [[13.]]\n","th [[ 14.  24.  21.  26.  44.  21.   6. -24.  54. -21.]] th0 [[14.]]\n","th [[ 13.  23.  18.  25.  41.  12.   5. -27.  45. -48.]] th0 [[13.]]\n","th [[ 12.  20.  15.  16.  32.   3. -22. -54.  18. -75.]] th0 [[12.]]\n","th [[ 13.  21.  16.  17.  33.   4. -21. -53.  19. -74.]] th0 [[13.]]\n","th [[ 14.  23.  18.  21.  37.   8. -13. -45.  27. -66.]] th0 [[14.]]\n","th [[ 15.  25.  21.  25.  43.  17.  -5. -33.  45. -39.]] th0 [[15.]]\n","th [[ 14.  22.  18.  16.  34.   8. -32. -60.  18. -66.]] th0 [[14.]]\n","th [[ 15.  23.  19.  17.  35.   9. -31. -59.  19. -65.]] th0 [[15.]]\n","th [[ 16.  25.  21.  21.  39.  13. -23. -51.  27. -57.]] th0 [[16.]]\n","th [[ 17.  27.  24.  25.  45.  22. -15. -39.  45. -30.]] th0 [[17.]]\n","th [[ 18.  31.  25.  41.  49.  23.  49. -23.  49. -29.]] th0 [[18.]]\n","th [[ 17.  30.  22.  40.  46.  14.  48. -26.  40. -56.]] th0 [[17.]]\n","th [[ 16.  27.  19.  31.  37.   5.  21. -53.  13. -83.]] th0 [[16.]]\n","th [[ 17.  29.  21.  35.  41.   9.  29. -45.  21. -75.]] th0 [[17.]]\n","th [[ 16.  27.  20.  31.  39.   8.  21. -49.  19. -76.]] th0 [[16.]]\n","th [[ 17.  29.  23.  35.  45.  17.  29. -37.  37. -49.]] th0 [[17.]]\n","th [[ 16.  26.  20.  26.  36.   8.   2. -64.  10. -76.]] th0 [[16.]]\n","th [[ 17.  28.  22.  30.  40.  12.  10. -56.  18. -68.]] th0 [[17.]]\n","th [[ 16.  26.  21.  26.  38.  11.   2. -60.  16. -69.]] th0 [[16.]]\n","th [[ 17.  28.  24.  30.  44.  20.  10. -48.  34. -42.]] th0 [[17.]]\n","th [[ 16.  27.  22.  29.  42.  16.   9. -50.  30. -50.]] th0 [[16.]]\n","th [[ 15.  25.  21.  25.  40.  15.   1. -54.  28. -51.]] th0 [[15.]]\n","th [[ 16.  27.  24.  29.  46.  24.   9. -42.  46. -24.]] th0 [[16.]]\n","th [[ 15.  26.  21.  28.  43.  15.   8. -45.  37. -51.]] th0 [[15.]]\n","th [[ 14.  24.  20.  24.  41.  14.   0. -49.  35. -52.]] th0 [[14.]]\n","th [[ 15.  26.  23.  28.  47.  23.   8. -37.  53. -25.]] th0 [[15.]]\n","th [[ 14.  25.  20.  27.  44.  14.   7. -40.  44. -52.]] th0 [[14.]]\n","th [[ 13.  23.  19.  23.  42.  13.  -1. -44.  42. -53.]] th0 [[13.]]\n","th [[ 14.  25.  22.  27.  48.  22.   7. -32.  60. -26.]] th0 [[14.]]\n","th [[ 13.  24.  19.  26.  45.  13.   6. -35.  51. -53.]] th0 [[13.]]\n","th [[ 12.  21.  16.  17.  36.   4. -21. -62.  24. -80.]] th0 [[12.]]\n","th [[ 13.  22.  17.  18.  37.   5. -20. -61.  25. -79.]] th0 [[13.]]\n","th [[ 14.  24.  19.  22.  41.   9. -12. -53.  33. -71.]] th0 [[14.]]\n","th [[ 15.  26.  22.  26.  47.  18.  -4. -41.  51. -44.]] th0 [[15.]]\n","th [[ 14.  25.  20.  25.  45.  14.  -5. -43.  47. -52.]] th0 [[14.]]\n","th [[ 13.  23.  19.  21.  43.  13. -13. -47.  45. -53.]] th0 [[13.]]\n","th [[ 14.  25.  22.  25.  49.  22.  -5. -35.  63. -26.]] th0 [[14.]]\n","th [[ 13.  24.  19.  24.  46.  13.  -6. -38.  54. -53.]] th0 [[13.]]\n","th [[ 12.  22.  18.  20.  44.  12. -14. -42.  52. -54.]] th0 [[12.]]\n","th [[ 13.  24.  21.  24.  50.  21.  -6. -30.  70. -27.]] th0 [[13.]]\n","th [[ 12.  23.  18.  23.  47.  12.  -7. -33.  61. -54.]] th0 [[12.]]\n","th [[ 11.  21.  17.  19.  45.  11. -15. -37.  59. -55.]] th0 [[11.]]\n","th [[ 12.  23.  20.  23.  51.  20.  -7. -25.  77. -28.]] th0 [[12.]]\n","th [[ 11.  22.  17.  22.  48.  11.  -8. -28.  68. -55.]] th0 [[11.]]\n","th [[ 10.  19.  14.  13.  39.   2. -35. -55.  41. -82.]] th0 [[10.]]\n","th [[ 11.  20.  15.  14.  40.   3. -34. -54.  42. -81.]] th0 [[11.]]\n","th [[ 12.  22.  17.  18.  44.   7. -26. -46.  50. -73.]] th0 [[12.]]\n","th [[ 13.  24.  20.  22.  50.  16. -18. -34.  68. -46.]] th0 [[13.]]\n","th [[ 14.  28.  21.  38.  54.  17.  46. -18.  72. -45.]] th0 [[14.]]\n","th [[ 13.  25.  18.  29.  45.   8.  19. -45.  45. -72.]] th0 [[13.]]\n","th [[ 12.  23.  17.  25.  43.   7.  11. -49.  43. -73.]] th0 [[12.]]\n","th [[ 13.  25.  20.  29.  49.  16.  19. -37.  61. -46.]] th0 [[13.]]\n","th [[ 12.  22.  17.  20.  40.   7.  -8. -64.  34. -73.]] th0 [[12.]]\n","th [[ 13.  24.  19.  24.  44.  11.   0. -56.  42. -65.]] th0 [[13.]]\n","th [[ 12.  22.  18.  20.  42.  10.  -8. -60.  40. -66.]] th0 [[12.]]\n","th [[ 13.  24.  21.  24.  48.  19.   0. -48.  58. -39.]] th0 [[13.]]\n","th [[ 12.  21.  18.  15.  39.  10. -27. -75.  31. -66.]] th0 [[12.]]\n","th [[ 13.  22.  19.  16.  40.  11. -26. -74.  32. -65.]] th0 [[13.]]\n","th [[ 14.  24.  21.  20.  44.  15. -18. -66.  40. -57.]] th0 [[14.]]\n","th [[ 15.  26.  24.  24.  50.  24. -10. -54.  58. -30.]] th0 [[15.]]\n","th [[ 16.  30.  25.  40.  54.  25.  54. -38.  62. -29.]] th0 [[16.]]\n","th [[ 15.  29.  22.  39.  51.  16.  53. -41.  53. -56.]] th0 [[15.]]\n","th [[ 14.  26.  19.  30.  42.   7.  26. -68.  26. -83.]] th0 [[14.]]\n","th [[ 15.  28.  21.  34.  46.  11.  34. -60.  34. -75.]] th0 [[15.]]\n","th [[ 14.  26.  20.  30.  44.  10.  26. -64.  32. -76.]] th0 [[14.]]\n","th [[ 15.  28.  23.  34.  50.  19.  34. -52.  50. -49.]] th0 [[15.]]\n","th [[ 14.  25.  20.  25.  41.  10.   7. -79.  23. -76.]] th0 [[14.]]\n","th [[ 15.  27.  22.  29.  45.  14.  15. -71.  31. -68.]] th0 [[15.]]\n","th [[ 14.  25.  21.  25.  43.  13.   7. -75.  29. -69.]] th0 [[14.]]\n","th [[ 15.  27.  24.  29.  49.  22.  15. -63.  47. -42.]] th0 [[15.]]\n","th [[ 14.  26.  22.  28.  47.  18.  14. -65.  43. -50.]] th0 [[14.]]\n","th [[ 13.  24.  21.  24.  45.  17.   6. -69.  41. -51.]] th0 [[13.]]\n","th [[ 14.  26.  24.  28.  51.  26.  14. -57.  59. -24.]] th0 [[14.]]\n","th [[ 13.  25.  21.  27.  48.  17.  13. -60.  50. -51.]] th0 [[13.]]\n","th [[ 12.  23.  20.  23.  46.  16.   5. -64.  48. -52.]] th0 [[12.]]\n","th [[ 13.  25.  23.  27.  52.  25.  13. -52.  66. -25.]] th0 [[13.]]\n","th [[ 12.  24.  20.  26.  49.  16.  12. -55.  57. -52.]] th0 [[12.]]\n","th [[ 11.  22.  19.  22.  47.  15.   4. -59.  55. -53.]] th0 [[11.]]\n","th [[ 12.  24.  22.  26.  53.  24.  12. -47.  73. -26.]] th0 [[12.]]\n","th [[ 11.  23.  19.  25.  50.  15.  11. -50.  64. -53.]] th0 [[11.]]\n","th [[ 10.  20.  16.  16.  41.   6. -16. -77.  37. -80.]] th0 [[10.]]\n","th [[ 11.  21.  17.  17.  42.   7. -15. -76.  38. -79.]] th0 [[11.]]\n","th [[ 12.  23.  19.  21.  46.  11.  -7. -68.  46. -71.]] th0 [[12.]]\n","th [[ 13.  25.  22.  25.  52.  20.   1. -56.  64. -44.]] th0 [[13.]]\n","th [[ 12.  22.  19.  16.  43.  11. -26. -83.  37. -71.]] th0 [[12.]]\n","th [[ 13.  23.  20.  17.  44.  12. -25. -82.  38. -70.]] th0 [[13.]]\n","th [[ 14.  25.  22.  21.  48.  16. -17. -74.  46. -62.]] th0 [[14.]]\n","th [[ 15.  27.  25.  25.  54.  25.  -9. -62.  64. -35.]] th0 [[15.]]\n","th [[ 16.  31.  26.  41.  58.  26.  55. -46.  68. -34.]] th0 [[16.]]\n","th [[ 15.  30.  23.  40.  55.  17.  54. -49.  59. -61.]] th0 [[15.]]\n","th [[ 14.  27.  20.  31.  46.   8.  27. -76.  32. -88.]] th0 [[14.]]\n","th [[ 15.  29.  22.  35.  50.  12.  35. -68.  40. -80.]] th0 [[15.]]\n","th [[ 14.  27.  21.  31.  48.  11.  27. -72.  38. -81.]] th0 [[14.]]\n","th [[ 15.  29.  24.  35.  54.  20.  35. -60.  56. -54.]] th0 [[15.]]\n","th [[ 14.  26.  21.  26.  45.  11.   8. -87.  29. -81.]] th0 [[14.]]\n","th [[ 15.  28.  23.  30.  49.  15.  16. -79.  37. -73.]] th0 [[15.]]\n","th [[ 14.  26.  22.  26.  47.  14.   8. -83.  35. -74.]] th0 [[14.]]\n","th [[ 15.  28.  25.  30.  53.  23.  16. -71.  53. -47.]] th0 [[15.]]\n","th [[ 14.  27.  23.  29.  51.  19.  15. -73.  49. -55.]] th0 [[14.]]\n","th [[ 13.  25.  22.  25.  49.  18.   7. -77.  47. -56.]] th0 [[13.]]\n","th [[ 14.  27.  25.  29.  55.  27.  15. -65.  65. -29.]] th0 [[14.]]\n","th [[ 13.  26.  22.  28.  52.  18.  14. -68.  56. -56.]] th0 [[13.]]\n","th [[ 12.  24.  21.  24.  50.  17.   6. -72.  54. -57.]] th0 [[12.]]\n","th [[ 13.  26.  24.  28.  56.  26.  14. -60.  72. -30.]] th0 [[13.]]\n","th [[ 12.  25.  21.  27.  53.  17.  13. -63.  63. -57.]] th0 [[12.]]\n","th [[ 11.  23.  20.  23.  51.  16.   5. -67.  61. -58.]] th0 [[11.]]\n","th [[ 12.  25.  23.  27.  57.  25.  13. -55.  79. -31.]] th0 [[12.]]\n","th [[ 11.  24.  20.  26.  54.  16.  12. -58.  70. -58.]] th0 [[11.]]\n","th [[ 10.  21.  17.  17.  45.   7. -15. -85.  43. -85.]] th0 [[10.]]\n","th [[ 11.  22.  18.  18.  46.   8. -14. -84.  44. -84.]] th0 [[11.]]\n","th [[ 12.  24.  20.  22.  50.  12.  -6. -76.  52. -76.]] th0 [[12.]]\n","th [[ 13.  26.  23.  26.  56.  21.   2. -64.  70. -49.]] th0 [[13.]]\n","th [[ 12.  25.  21.  25.  54.  17.   1. -66.  66. -57.]] th0 [[12.]]\n","th [[ 11.  23.  20.  21.  52.  16.  -7. -70.  64. -58.]] th0 [[11.]]\n","th [[ 12.  25.  23.  25.  58.  25.   1. -58.  82. -31.]] th0 [[12.]]\n","th [[ 11.  24.  20.  24.  55.  16.   0. -61.  73. -58.]] th0 [[11.]]\n","th [[ 10.  22.  19.  20.  53.  15.  -8. -65.  71. -59.]] th0 [[10.]]\n","th [[ 11.  24.  22.  24.  59.  24.   0. -53.  89. -32.]] th0 [[11.]]\n","th [[ 10.  23.  19.  23.  56.  15.  -1. -56.  80. -59.]] th0 [[10.]]\n","th [[  9.  20.  16.  14.  47.   6. -28. -83.  53. -86.]] th0 [[9.]]\n","th [[ 10.  21.  17.  15.  48.   7. -27. -82.  54. -85.]] th0 [[10.]]\n","th [[ 11.  23.  19.  19.  52.  11. -19. -74.  62. -77.]] th0 [[11.]]\n","th [[ 12.  25.  22.  23.  58.  20. -11. -62.  80. -50.]] th0 [[12.]]\n","th [[ 13.  29.  23.  39.  62.  21.  53. -46.  84. -49.]] th0 [[13.]]\n","th [[ 12.  26.  20.  30.  53.  12.  26. -73.  57. -76.]] th0 [[12.]]\n","th [[ 13.  28.  22.  34.  57.  16.  34. -65.  65. -68.]] th0 [[13.]]\n","th [[ 12.  26.  21.  30.  55.  15.  26. -69.  63. -69.]] th0 [[12.]]\n","th [[ 13.  28.  24.  34.  61.  24.  34. -57.  81. -42.]] th0 [[13.]]\n","th [[ 12.  27.  21.  33.  58.  15.  33. -60.  72. -69.]] th0 [[12.]]\n","th [[ 11.  24.  18.  24.  49.   6.   6. -87.  45. -96.]] th0 [[11.]]\n","th [[ 12.  26.  20.  28.  53.  10.  14. -79.  53. -88.]] th0 [[12.]]\n","th [[ 11.  24.  19.  24.  51.   9.   6. -83.  51. -89.]] th0 [[11.]]\n","th [[ 12.  26.  22.  28.  57.  18.  14. -71.  69. -62.]] th0 [[12.]]\n","th [[ 11.  24.  21.  24.  55.  17.   6. -75.  67. -63.]] th0 [[11.]]\n","th [[ 12.  26.  24.  28.  61.  26.  14. -63.  85. -36.]] th0 [[12.]]\n","th [[ 11.  25.  21.  27.  58.  17.  13. -66.  76. -63.]] th0 [[11.]]\n","th [[ 10.  23.  20.  23.  56.  16.   5. -70.  74. -64.]] th0 [[10.]]\n","th [[ 11.  25.  23.  27.  62.  25.  13. -58.  92. -37.]] th0 [[11.]]\n","th [[ 10.  24.  20.  26.  59.  16.  12. -61.  83. -64.]] th0 [[10.]]\n","th [[  9.  21.  17.  17.  50.   7. -15. -88.  56. -91.]] th0 [[9.]]\n","th [[ 10.  22.  18.  18.  51.   8. -14. -87.  57. -90.]] th0 [[10.]]\n","th [[ 11.  24.  20.  22.  55.  12.  -6. -79.  65. -82.]] th0 [[11.]]\n","th [[ 12.  26.  23.  26.  61.  21.   2. -67.  83. -55.]] th0 [[12.]]\n","th [[ 11.  23.  20.  17.  52.  12. -25. -94.  56. -82.]] th0 [[11.]]\n","th [[ 12.  25.  22.  21.  56.  16. -17. -86.  64. -74.]] th0 [[12.]]\n","th [[ 13.  27.  25.  25.  62.  25.  -9. -74.  82. -47.]] th0 [[13.]]\n","th [[ 14.  31.  26.  41.  66.  26.  55. -58.  86. -46.]] th0 [[14.]]\n","th [[ 13.  30.  23.  40.  63.  17.  54. -61.  77. -73.]] th0 [[13.]]\n","th [[  12.   27.   20.   31.   54.    8.   27.  -88.   50. -100.]] th0 [[12.]]\n","th [[ 13.  29.  22.  35.  58.  12.  35. -80.  58. -92.]] th0 [[13.]]\n","th [[ 12.  27.  21.  31.  56.  11.  27. -84.  56. -93.]] th0 [[12.]]\n","th [[ 13.  29.  24.  35.  62.  20.  35. -72.  74. -66.]] th0 [[13.]]\n","th [[ 12.  26.  21.  26.  53.  11.   8. -99.  47. -93.]] th0 [[12.]]\n","th [[ 13.  28.  23.  30.  57.  15.  16. -91.  55. -85.]] th0 [[13.]]\n","th [[ 12.  26.  22.  26.  55.  14.   8. -95.  53. -86.]] th0 [[12.]]\n","th [[ 13.  28.  25.  30.  61.  23.  16. -83.  71. -59.]] th0 [[13.]]\n","th [[ 12.  27.  23.  29.  59.  19.  15. -85.  67. -67.]] th0 [[12.]]\n","th [[ 11.  25.  22.  25.  57.  18.   7. -89.  65. -68.]] th0 [[11.]]\n","th [[ 12.  27.  25.  29.  63.  27.  15. -77.  83. -41.]] th0 [[12.]]\n","th [[ 11.  26.  22.  28.  60.  18.  14. -80.  74. -68.]] th0 [[11.]]\n","th [[ 10.  24.  21.  24.  58.  17.   6. -84.  72. -69.]] th0 [[10.]]\n","th [[ 11.  26.  24.  28.  64.  26.  14. -72.  90. -42.]] th0 [[11.]]\n","th [[ 10.  25.  21.  27.  61.  17.  13. -75.  81. -69.]] th0 [[10.]]\n","th [[  9.  23.  20.  23.  59.  16.   5. -79.  79. -70.]] th0 [[9.]]\n","th [[ 10.  25.  23.  27.  65.  25.  13. -67.  97. -43.]] th0 [[10.]]\n","th [[  9.  24.  20.  26.  62.  16.  12. -70.  88. -70.]] th0 [[9.]]\n","th [[  8.  21.  17.  17.  53.   7. -15. -97.  61. -97.]] th0 [[8.]]\n","th [[  9.  22.  18.  18.  54.   8. -14. -96.  62. -96.]] th0 [[9.]]\n","th [[ 10.  24.  20.  22.  58.  12.  -6. -88.  70. -88.]] th0 [[10.]]\n","th [[ 11.  26.  23.  26.  64.  21.   2. -76.  88. -61.]] th0 [[11.]]\n","th [[ 10.  25.  21.  25.  62.  17.   1. -78.  84. -69.]] th0 [[10.]]\n","th [[  9.  23.  20.  21.  60.  16.  -7. -82.  82. -70.]] th0 [[9.]]\n","th [[ 10.  25.  23.  25.  66.  25.   1. -70. 100. -43.]] th0 [[10.]]\n","th [[  9.  24.  20.  24.  63.  16.   0. -73.  91. -70.]] th0 [[9.]]\n","th [[  8.  22.  19.  20.  61.  15.  -8. -77.  89. -71.]] th0 [[8.]]\n","th [[  9.  24.  22.  24.  67.  24.   0. -65. 107. -44.]] th0 [[9.]]\n","th [[  8.  23.  19.  23.  64.  15.  -1. -68.  98. -71.]] th0 [[8.]]\n","th [[  7.  21.  18.  19.  62.  14.  -9. -72.  96. -72.]] th0 [[7.]]\n","th [[  8.  23.  21.  23.  68.  23.  -1. -60. 114. -45.]] th0 [[8.]]\n","th [[  7.  22.  18.  22.  65.  14.  -2. -63. 105. -72.]] th0 [[7.]]\n","th [[  6.  19.  15.  13.  56.   5. -29. -90.  78. -99.]] th0 [[6.]]\n","th [[  7.  20.  16.  14.  57.   6. -28. -89.  79. -98.]] th0 [[7.]]\n","th [[  8.  22.  18.  18.  61.  10. -20. -81.  87. -90.]] th0 [[8.]]\n","th [[  9.  24.  21.  22.  67.  19. -12. -69. 105. -63.]] th0 [[9.]]\n","th [[ 10.  28.  22.  38.  71.  20.  52. -53. 109. -62.]] th0 [[10.]]\n","th [[  9.  25.  19.  29.  62.  11.  25. -80.  82. -89.]] th0 [[9.]]\n","th [[  8.  23.  18.  25.  60.  10.  17. -84.  80. -90.]] th0 [[8.]]\n","th [[  9.  25.  21.  29.  66.  19.  25. -72.  98. -63.]] th0 [[9.]]\n","th [[  8.  22.  18.  20.  57.  10.  -2. -99.  71. -90.]] th0 [[8.]]\n","th [[  9.  24.  20.  24.  61.  14.   6. -91.  79. -82.]] th0 [[9.]]\n","th [[  8.  22.  19.  20.  59.  13.  -2. -95.  77. -83.]] th0 [[8.]]\n","th [[  9.  24.  22.  24.  65.  22.   6. -83.  95. -56.]] th0 [[9.]]\n","th [[   8.   21.   19.   15.   56.   13.  -21. -110.   68.  -83.]] th0 [[8.]]\n","th [[   9.   22.   20.   16.   57.   14.  -20. -109.   69.  -82.]] th0 [[9.]]\n","th [[  10.   24.   22.   20.   61.   18.  -12. -101.   77.  -74.]] th0 [[10.]]\n","th [[ 11.  26.  25.  24.  67.  27.  -4. -89.  95. -47.]] th0 [[11.]]\n","th [[ 12.  30.  26.  40.  71.  28.  60. -73.  99. -46.]] th0 [[12.]]\n","th [[ 11.  29.  23.  39.  68.  19.  59. -76.  90. -73.]] th0 [[11.]]\n","th [[  10.   26.   20.   30.   59.   10.   32. -103.   63. -100.]] th0 [[10.]]\n","th [[ 11.  28.  22.  34.  63.  14.  40. -95.  71. -92.]] th0 [[11.]]\n","th [[ 10.  26.  21.  30.  61.  13.  32. -99.  69. -93.]] th0 [[10.]]\n","th [[ 11.  28.  24.  34.  67.  22.  40. -87.  87. -66.]] th0 [[11.]]\n","th [[  10.   25.   21.   25.   58.   13.   13. -114.   60.  -93.]] th0 [[10.]]\n","th [[  11.   27.   23.   29.   62.   17.   21. -106.   68.  -85.]] th0 [[11.]]\n","th [[  10.   25.   22.   25.   60.   16.   13. -110.   66.  -86.]] th0 [[10.]]\n","th [[ 11.  27.  25.  29.  66.  25.  21. -98.  84. -59.]] th0 [[11.]]\n","th [[  10.   26.   23.   28.   64.   21.   20. -100.   80.  -67.]] th0 [[10.]]\n","th [[   9.   24.   22.   24.   62.   20.   12. -104.   78.  -68.]] th0 [[9.]]\n","th [[ 10.  26.  25.  28.  68.  29.  20. -92.  96. -41.]] th0 [[10.]]\n","th [[  9.  25.  22.  27.  65.  20.  19. -95.  87. -68.]] th0 [[9.]]\n","th [[  8.  23.  21.  23.  63.  19.  11. -99.  85. -69.]] th0 [[8.]]\n","th [[  9.  25.  24.  27.  69.  28.  19. -87. 103. -42.]] th0 [[9.]]\n","th [[  8.  24.  21.  26.  66.  19.  18. -90.  94. -69.]] th0 [[8.]]\n","th [[  7.  22.  20.  22.  64.  18.  10. -94.  92. -70.]] th0 [[7.]]\n","th [[  8.  24.  23.  26.  70.  27.  18. -82. 110. -43.]] th0 [[8.]]\n","th [[  7.  23.  20.  25.  67.  18.  17. -85. 101. -70.]] th0 [[7.]]\n","th [[   6.   20.   17.   16.   58.    9.  -10. -112.   74.  -97.]] th0 [[6.]]\n","th [[   7.   21.   18.   17.   59.   10.   -9. -111.   75.  -96.]] th0 [[7.]]\n","th [[   8.   23.   20.   21.   63.   14.   -1. -103.   83.  -88.]] th0 [[8.]]\n","th [[  9.  25.  23.  25.  69.  23.   7. -91. 101. -61.]] th0 [[9.]]\n","th [[   8.   22.   20.   16.   60.   14.  -20. -118.   74.  -88.]] th0 [[8.]]\n","th [[   9.   23.   21.   17.   61.   15.  -19. -117.   75.  -87.]] th0 [[9.]]\n","th [[  10.   25.   23.   21.   65.   19.  -11. -109.   83.  -79.]] th0 [[10.]]\n","th [[ 11.  27.  26.  25.  71.  28.  -3. -97. 101. -52.]] th0 [[11.]]\n","th [[ 12.  31.  27.  41.  75.  29.  61. -81. 105. -51.]] th0 [[12.]]\n","th [[ 11.  30.  24.  40.  72.  20.  60. -84.  96. -78.]] th0 [[11.]]\n","th [[  10.   27.   21.   31.   63.   11.   33. -111.   69. -105.]] th0 [[10.]]\n","th [[  11.   29.   23.   35.   67.   15.   41. -103.   77.  -97.]] th0 [[11.]]\n","th [[  10.   27.   22.   31.   65.   14.   33. -107.   75.  -98.]] th0 [[10.]]\n","th [[ 11.  29.  25.  35.  71.  23.  41. -95.  93. -71.]] th0 [[11.]]\n","th [[  10.   26.   22.   26.   62.   14.   14. -122.   66.  -98.]] th0 [[10.]]\n","th [[  11.   28.   24.   30.   66.   18.   22. -114.   74.  -90.]] th0 [[11.]]\n","th [[  10.   26.   23.   26.   64.   17.   14. -118.   72.  -91.]] th0 [[10.]]\n","th [[  11.   28.   26.   30.   70.   26.   22. -106.   90.  -64.]] th0 [[11.]]\n","th [[  10.   27.   24.   29.   68.   22.   21. -108.   86.  -72.]] th0 [[10.]]\n","th [[   9.   25.   23.   25.   66.   21.   13. -112.   84.  -73.]] th0 [[9.]]\n","th [[  10.   27.   26.   29.   72.   30.   21. -100.  102.  -46.]] th0 [[10.]]\n","th [[   9.   26.   23.   28.   69.   21.   20. -103.   93.  -73.]] th0 [[9.]]\n","th [[   9.   26.   23.   28.   69.   21.   20. -103.   93.  -73.]] th0 [[9.]]\n","Final score 6\n","Params [[   9.   26.   23.   28.   69.   21.   20. -103.   93.  -73.]] [[9.]]\n"],"name":"stdout"}]},{"metadata":{"id":"GcgPe4-XQ8-b","colab_type":"text"},"cell_type":"markdown","source":["# Experiments"]},{"metadata":{"id":"erNybvgGRXCf","colab_type":"text"},"cell_type":"markdown","source":["## 4) Evaluating algorithmic and feature choices for AUTO data\n","\n","We now want to build a classifier for the auto data, focusing on the\n","numeric data.  In the code file for this part of the assignment, we have supplied you\n","with the `load_auto_data` function, that can be used to read the\n","relevant .tsv file.  It will return a list of dictionaries, one for each data item.\n","\n","We then have to specify what feature function to use for each column\n","in the data.  The file `hw3_part2_main.py` has an example for constructing\n","the data and label arrays using `raw` feature function for all the columns.\n","Look at the definition of `features` in `hw3_part2_main.py`, this indicates a feature name to\n","use and then a feature function, there are three defined in the\n","`code_for_hw3_part2.py` file (`raw`, `standard` and `one_hot`).  `raw` just uses\n","the original value, `standard` subtracts out the mean value and\n","divides by the standard deviation and `one_hot` does the encoding\n","described in the notes.\n","\n","The function `auto_data_and_labels` will process the dictionaries and\n","return <tt>data, labels</tt> where <tt>data</tt> are arrays of\n","dimension $(d, 392)$, with $d$ the total number of features specified,\n","and <tt>labels</tt> is of dimension $(1, 392)$.  The data in the file\n","is sorted by class, but it will be shuffled when you read it in."]},{"metadata":{"id":"oyNA08jC0smc","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"yfOrmU1XdFCZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":523},"outputId":"a8d677dc-93de-4415-c8f5-251582318900","executionInfo":{"status":"ok","timestamp":1550865676371,"user_tz":300,"elapsed":5010,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["# Your code here to process the auto data\n","from functools import partial\n","for f in [features_raw, features_std]:\n","  auto_data, auto_labels = hw3.auto_data_and_labels(auto_data_all, f)\n","  for iter_num in (1, 10, 50):\n","    params={'T':iter_num}\n","    for learner in (hw3.perceptron, hw3.averaged_perceptron):\n","      print('features are ', f, 'T is ', iter_num, 'learner is ', learner)\n","\n","      print(hw3.xval_learning_alg(partial(learner, params=params), auto_data, auto_labels, k=10))\n"],"execution_count":39,"outputs":[{"output_type":"stream","text":["avg and std {}\n","entries in one_hot field {}\n","features are  [('cylinders', <function raw at 0x7fc10e60d6a8>), ('displacement', <function raw at 0x7fc10e60d6a8>), ('horsepower', <function raw at 0x7fc10e60d6a8>), ('weight', <function raw at 0x7fc10e60d6a8>), ('acceleration', <function raw at 0x7fc10e60d6a8>), ('origin', <function raw at 0x7fc10e60d6a8>)] T is  1 learner is  <function perceptron at 0x7fc10e60d158>\n","0.6526282051282052\n","features are  [('cylinders', <function raw at 0x7fc10e60d6a8>), ('displacement', <function raw at 0x7fc10e60d6a8>), ('horsepower', <function raw at 0x7fc10e60d6a8>), ('weight', <function raw at 0x7fc10e60d6a8>), ('acceleration', <function raw at 0x7fc10e60d6a8>), ('origin', <function raw at 0x7fc10e60d6a8>)] T is  1 learner is  <function averaged_perceptron at 0x7fc10e60d1e0>\n","0.8441025641025641\n","features are  [('cylinders', <function raw at 0x7fc10e60d6a8>), ('displacement', <function raw at 0x7fc10e60d6a8>), ('horsepower', <function raw at 0x7fc10e60d6a8>), ('weight', <function raw at 0x7fc10e60d6a8>), ('acceleration', <function raw at 0x7fc10e60d6a8>), ('origin', <function raw at 0x7fc10e60d6a8>)] T is  10 learner is  <function perceptron at 0x7fc10e60d158>\n","0.7423076923076924\n","features are  [('cylinders', <function raw at 0x7fc10e60d6a8>), ('displacement', <function raw at 0x7fc10e60d6a8>), ('horsepower', <function raw at 0x7fc10e60d6a8>), ('weight', <function raw at 0x7fc10e60d6a8>), ('acceleration', <function raw at 0x7fc10e60d6a8>), ('origin', <function raw at 0x7fc10e60d6a8>)] T is  10 learner is  <function averaged_perceptron at 0x7fc10e60d1e0>\n","0.8366025641025641\n","features are  [('cylinders', <function raw at 0x7fc10e60d6a8>), ('displacement', <function raw at 0x7fc10e60d6a8>), ('horsepower', <function raw at 0x7fc10e60d6a8>), ('weight', <function raw at 0x7fc10e60d6a8>), ('acceleration', <function raw at 0x7fc10e60d6a8>), ('origin', <function raw at 0x7fc10e60d6a8>)] T is  50 learner is  <function perceptron at 0x7fc10e60d158>\n","0.6909615384615384\n","features are  [('cylinders', <function raw at 0x7fc10e60d6a8>), ('displacement', <function raw at 0x7fc10e60d6a8>), ('horsepower', <function raw at 0x7fc10e60d6a8>), ('weight', <function raw at 0x7fc10e60d6a8>), ('acceleration', <function raw at 0x7fc10e60d6a8>), ('origin', <function raw at 0x7fc10e60d6a8>)] T is  50 learner is  <function averaged_perceptron at 0x7fc10e60d1e0>\n","0.8366025641025641\n","avg and std {'displacement': (388.3482142857143, 302.0458123396403), 'horsepower': (509.3545918367347, 333.6521151716361), 'weight': (2977.5841836734694, 848.3184465698365), 'acceleration': (15.541326530612228, 2.7553429127509963)}\n","entries in one_hot field {'cylinders': [3.0, 4.0, 5.0, 6.0, 8.0], 'origin': [1.0, 2.0, 3.0]}\n","features are  [('cylinders', <function one_hot at 0x7fc10e60d730>), ('displacement', <function standard at 0x7fc10e60d620>), ('horsepower', <function standard at 0x7fc10e60d620>), ('weight', <function standard at 0x7fc10e60d620>), ('acceleration', <function standard at 0x7fc10e60d620>), ('origin', <function one_hot at 0x7fc10e60d730>)] T is  1 learner is  <function perceptron at 0x7fc10e60d158>\n","0.7908333333333333\n","features are  [('cylinders', <function one_hot at 0x7fc10e60d730>), ('displacement', <function standard at 0x7fc10e60d620>), ('horsepower', <function standard at 0x7fc10e60d620>), ('weight', <function standard at 0x7fc10e60d620>), ('acceleration', <function standard at 0x7fc10e60d620>), ('origin', <function one_hot at 0x7fc10e60d730>)] T is  1 learner is  <function averaged_perceptron at 0x7fc10e60d1e0>\n","0.9004487179487182\n","features are  [('cylinders', <function one_hot at 0x7fc10e60d730>), ('displacement', <function standard at 0x7fc10e60d620>), ('horsepower', <function standard at 0x7fc10e60d620>), ('weight', <function standard at 0x7fc10e60d620>), ('acceleration', <function standard at 0x7fc10e60d620>), ('origin', <function one_hot at 0x7fc10e60d730>)] T is  10 learner is  <function perceptron at 0x7fc10e60d158>\n","0.8061538461538461\n","features are  [('cylinders', <function one_hot at 0x7fc10e60d730>), ('displacement', <function standard at 0x7fc10e60d620>), ('horsepower', <function standard at 0x7fc10e60d620>), ('weight', <function standard at 0x7fc10e60d620>), ('acceleration', <function standard at 0x7fc10e60d620>), ('origin', <function one_hot at 0x7fc10e60d730>)] T is  10 learner is  <function averaged_perceptron at 0x7fc10e60d1e0>\n","0.8979487179487181\n","features are  [('cylinders', <function one_hot at 0x7fc10e60d730>), ('displacement', <function standard at 0x7fc10e60d620>), ('horsepower', <function standard at 0x7fc10e60d620>), ('weight', <function standard at 0x7fc10e60d620>), ('acceleration', <function standard at 0x7fc10e60d620>), ('origin', <function one_hot at 0x7fc10e60d730>)] T is  50 learner is  <function perceptron at 0x7fc10e60d158>\n","0.8060256410256409\n","features are  [('cylinders', <function one_hot at 0x7fc10e60d730>), ('displacement', <function standard at 0x7fc10e60d620>), ('horsepower', <function standard at 0x7fc10e60d620>), ('weight', <function standard at 0x7fc10e60d620>), ('acceleration', <function standard at 0x7fc10e60d620>), ('origin', <function one_hot at 0x7fc10e60d730>)] T is  50 learner is  <function averaged_perceptron at 0x7fc10e60d1e0>\n","0.9005128205128207\n"],"name":"stdout"}]},{"metadata":{"id":"b9Ajh1RPx0lM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":280},"outputId":"2d3ca29b-d378-4840-a0f3-ca84e6ed106c","executionInfo":{"status":"ok","timestamp":1550865960927,"user_tz":300,"elapsed":331,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["auto_data, auto_labels = hw3.auto_data_and_labels(auto_data_all, features_std)\n","hw3.averaged_perceptron(auto_data, auto_labels, {'T': 1})"],"execution_count":40,"outputs":[{"output_type":"stream","text":["avg and std {'displacement': (388.3482142857143, 302.0458123396403), 'horsepower': (509.3545918367347, 333.6521151716361), 'weight': (2977.5841836734694, 848.3184465698365), 'acceleration': (15.541326530612228, 2.7553429127509963)}\n","entries in one_hot field {'cylinders': [3.0, 4.0, 5.0, 6.0, 8.0], 'origin': [1.0, 2.0, 3.0]}\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(array([[-0.25510204],\n","        [ 0.98469388],\n","        [ 0.        ],\n","        [ 0.4744898 ],\n","        [-0.52040816],\n","        [ 0.0977406 ],\n","        [-0.89763413],\n","        [-1.84711922],\n","        [ 0.06270238],\n","        [-0.04591837],\n","        [ 0.98469388],\n","        [-0.25510204]]), array([[0.68367347]]))"]},"metadata":{"tags":[]},"execution_count":40}]},{"metadata":{"id":"sh-D5bvTbizf","colab_type":"text"},"cell_type":"markdown","source":["## 5) Evaluating algorithmic and feature choices for review data\n","\n","We have supplied you with the `load_review_data`\n","function, that can be used to read a .tsv file and return the labels\n","and texts. We have also supplied you with the `bag_of_words` function,\n","which takes the raw data and returns a dictionary of unigram\n","words. The resulting dictionary is an input to\n","`extract_bow_feature_vectors` which computes a feature matrix of ones\n","and zeros that can be used as the input for the classification\n","algorithms.  The file `hw3_part2_main.py` has code for constructing\n","the data and label arrays.  Using these arrays and our implementation\n","of the learning algorithms, you will be able to compute $\\theta$ and\n","$\\theta_0$.  You will need to add your (or the one written by staff)\n","implementation of perceptron and averaged perceptron."]},{"metadata":{"id":"5gHVvGl2bsps","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e4607a88-c3d4-44fd-ec05-d30a5b92e8ce","executionInfo":{"status":"ok","timestamp":1550866501313,"user_tz":300,"elapsed":2915,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["# Returns lists of dictionaries.  Keys are the column names, 'sentiment' and 'text'.\n","# The train data has 10,000 examples\n","review_data = hw3.load_review_data('reviews.tsv')\n","\n","# Lists texts of reviews and list of labels (1 or -1)\n","review_texts, review_label_list = zip(*((sample['text'], sample['sentiment']) for sample in review_data))\n","\n","# The dictionary of all the words for \"bag of words\"\n","dictionary = hw3.bag_of_words(review_texts)\n","\n","# The standard data arrays for the bag of words\n","review_bow_data = hw3.extract_bow_feature_vectors(review_texts, dictionary)\n","review_labels = hw3.rv(review_label_list)\n","print('review_bow_data and labels shape', review_bow_data.shape, review_labels.shape)"],"execution_count":41,"outputs":[{"output_type":"stream","text":["review_bow_data and labels shape (19945, 10000) (1, 10000)\n"],"name":"stdout"}]},{"metadata":{"id":"wR9S-6DsdDFF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":225},"outputId":"654fa7bf-362f-475c-96dc-70eca6800146","executionInfo":{"status":"ok","timestamp":1550867166800,"user_tz":300,"elapsed":551478,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["# Your code here to process the review data\n","for T in (5, 10, 50):\n","  params={'T': T}\n","  for learner in (hw3.perceptron, hw3.averaged_perceptron):\n","    print('T is ', T, 'learner is ', learner)\n","\n","    print(\n","          hw3.xval_learning_alg(partial(\n","              learner, params=params), review_bow_data, review_labels, k=10))\n"],"execution_count":44,"outputs":[{"output_type":"stream","text":["T is  50 learner is  <function perceptron at 0x7fc10e60d158>\n","0.7857000000000001\n","T is  50 learner is  <function averaged_perceptron at 0x7fc10e60d1e0>\n","0.8254999999999999\n","T is  50 learner is  <function perceptron at 0x7fc10e60d158>\n","0.7871\n","T is  50 learner is  <function averaged_perceptron at 0x7fc10e60d1e0>\n","0.8237\n","T is  50 learner is  <function perceptron at 0x7fc10e60d158>\n","0.8036\n","T is  50 learner is  <function averaged_perceptron at 0x7fc10e60d1e0>\n","0.8157\n"],"name":"stdout"}]},{"metadata":{"id":"mSaI2fDE3spS","colab_type":"code","colab":{}},"cell_type":"code","source":["# run averaged perceptron with T as 10\n","th, th0 = hw3.averaged_perceptron(review_bow_data, review_labels, params={'T':10})"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0k2rEzKZ7T-z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":156},"outputId":"4604f2fb-4260-4a5c-d175-f1a52d73b4b0","executionInfo":{"status":"ok","timestamp":1550867849245,"user_tz":300,"elapsed":355,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["print(th.shape)\n","print(th)"],"execution_count":66,"outputs":[{"output_type":"stream","text":["(19945, 1)\n","[[ 0.15984]\n"," [-2.74048]\n"," [-1.23668]\n"," ...\n"," [ 0.     ]\n"," [-1.2001 ]\n"," [ 0.     ]]\n"],"name":"stdout"}]},{"metadata":{"id":"o_mHi6hM5v5e","colab_type":"code","colab":{}},"cell_type":"code","source":["ind_most_pos = np.argsort(th, axis=0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DzK3t5t76Xek","colab_type":"code","colab":{}},"cell_type":"code","source":["dict_keys= list(dictionary.keys())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4KDhR6Db5wEf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":382},"outputId":"12a5de5d-299c-47dc-bc29-200b86df7426","executionInfo":{"status":"ok","timestamp":1550867950739,"user_tz":300,"elapsed":425,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["strs = []\n","for top_key in ind_most_pos[-10:, 0]:\n","  key_name = dict_keys[top_key]\n","  print(key_name, top_key)\n","  print(dictionary[key_name])\n","  strs.append(key_name)\n","  \n","  \n","print(strs)"],"execution_count":74,"outputs":[{"output_type":"stream","text":["great 56\n","56\n","individually 2213\n","2213\n","bright 2329\n","2329\n","yummy 1476\n","1476\n","skeptical 2413\n","2413\n","perfect 356\n","356\n","easily 1896\n","1896\n","satisfied 1105\n","1105\n","delicious 348\n","348\n","excellent 1041\n","1041\n","['great', 'individually', 'bright', 'yummy', 'skeptical', 'perfect', 'easily', 'satisfied', 'delicious', 'excellent']\n"],"name":"stdout"}]},{"metadata":{"id":"UsbRkTuE79Ut","colab_type":"code","colab":{}},"cell_type":"code","source":["# to find the most positive/most negative reviews we looks for those with the largest/smallest signed distance to  the hyperplane"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qbqHMbrubt5t","colab_type":"text"},"cell_type":"markdown","source":["## 6) Evaluating features for MNIST data\n","\n","\n","This problem explores how well the perceptron algorithm works to <a\n","href=\"http://neuralnetworksanddeeplearning.com/chap1.html\">classify\n","images of handwritten digits</a>, from the well-known (\"MNIST\")\n","dataset, buiding on your thoughts from lab about extracting features\n","from images.  This exercise will highlight how important feature\n","extraction is, before linear classification is done, using algorithms\n","such as the perceptron.\n","\n","<b>Dataset setup</b>\n","\n","Often, it may be easier to work with a vector whose spatial orientation is preserved.\n","In previous parts, we have represented features as one long feature vector.\n","For images, however, we often represent a $m$ by $n$ image\n","as a `(m,n)` array, rather than a `(mn,1)` array\n","(as the previous parts have done).\n","\n","In the code file, we have supplied you with the `load_mnist_data` function,\n","which will read from the provided image files and populate a dictionary,\n","with image and label vectors for each numerical digit from 0 to 9.\n","These images are already shaped as `(m,n)` arrays."]},{"metadata":{"id":"HU0LYxtDQknD","colab_type":"code","colab":{}},"cell_type":"code","source":["# data is dimension d by n\n","# labels is dimension 1 by n\n","# T is a positive integer number of steps to run\n","# Perceptron algorithm with offset.\n","# data is dimension d by n\n","# labels is dimension 1 by n\n","# T is a positive integer number of steps to run\n","def perceptron(data, labels, params = {}, hook = None):\n","    # if T not in params, default to 50\n","    T = params.get('T', 50)\n","    (d, n) = data.shape\n","\n","    theta = np.zeros((d, 1)); theta_0 = np.zeros((1, 1))\n","    for t in range(T):\n","        for i in range(n):\n","            x = data[:,i:i+1]\n","            y = labels[:,i:i+1]\n","            if y * positive(x, theta, theta_0) <= 0.0:\n","                theta = theta + y * x\n","                theta_0 = theta_0 + y\n","                if hook: hook((theta, theta_0))\n","    return theta, theta_0\n","\n","def averaged_perceptron(data, labels, params = {}, hook = None):\n","    T = params.get('T', 100)\n","    (d, n) = data.shape\n","\n","    theta = np.zeros((d, 1)); theta_0 = np.zeros((1, 1))\n","    theta_sum = theta.copy()\n","    theta_0_sum = theta_0.copy()\n","    for t in range(T):\n","        for i in range(n):\n","            x = data[:,i:i+1]\n","            y = labels[:,i:i+1]\n","            if y * positive(x, theta, theta_0) <= 0.0:\n","                theta = theta + y * x\n","                theta_0 = theta_0 + y\n","                if hook: hook((theta, theta_0))\n","            theta_sum = theta_sum + theta\n","            theta_0_sum = theta_0_sum + theta_0\n","    theta_avg = theta_sum / (T*n)\n","    theta_0_avg = theta_0_sum / (T*n)\n","    if hook: hook((theta_avg, theta_0_avg))\n","    return theta_avg, theta_0_avg\n","\n","def positive(x, th, th0):\n","    return np.sign(th.T@x + th0)\n","\n","def score(data, labels, th, th0):\n","    return np.sum(positive(data, th, th0) == labels)\n","\n","def eval_classifier(learner, data_train, labels_train, data_test, labels_test, params={}):\n","    th, th0 = learner(data_train, labels_train, params=params)\n","    return score(data_test, labels_test, th, th0)/data_test.shape[1]\n","\n","def xval_learning_alg(learner, data, labels, k, params={}):\n","    _, n = data.shape\n","    idx = list(range(n))\n","    np.random.seed(0)\n","    np.random.shuffle(idx)\n","    data, labels = data[:,idx], labels[:,idx]\n","\n","    s_data = np.array_split(data, k, axis=1)\n","    s_labels = np.array_split(labels, k, axis=1)\n","\n","    score_sum = 0\n","    for i in range(k):\n","        data_train = np.concatenate(s_data[:i] + s_data[i+1:], axis=1)\n","        labels_train = np.concatenate(s_labels[:i] + s_labels[i+1:], axis=1)\n","        data_test = np.array(s_data[i])\n","        labels_test = np.array(s_labels[i])\n","        score_sum += eval_classifier(learner, data_train, labels_train,\n","                                              data_test, labels_test, params=params)\n","    return score_sum/k\n","\n","\n","def get_classification_accuracy(data, labels):\n","    \"\"\"\n","    @param data (d,n) array\n","    @param labels (1,n) array\n","    \"\"\"\n","    return xval_learning_alg(lambda data, labels: perceptron(data, labels, {\"T\": 50}), data, labels, 10)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_6xT_UA2cJMe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"d2cc4c38-d567-40d6-d6d3-7682f154a6c4","executionInfo":{"status":"ok","timestamp":1550890460788,"user_tz":300,"elapsed":1347,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["mnist_data_all = hw3.load_mnist_data(range(10))\n","\n","print('mnist_data_all loaded. shape of single images is', mnist_data_all[0][\"images\"][0].shape)\n","\n","# HINT: change the [0] and [1] if you want to access different images\n","d0 = mnist_data_all[0][\"images\"]\n","d1 = mnist_data_all[1][\"images\"]\n","y0 = np.repeat(-1, len(d0)).reshape(1,-1)\n","y1 = np.repeat(1, len(d1)).reshape(1,-1)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["mnist_data_all loaded. shape of single images is (28, 28)\n"],"name":"stdout"}]},{"metadata":{"id":"0UbEL8p2BRWB","colab_type":"code","colab":{}},"cell_type":"code","source":["d2 = mnist_data_all[2][\"images\"]\n","d4 = mnist_data_all[4][\"images\"]\n","d6 = mnist_data_all[6][\"images\"]\n","d8 = mnist_data_all[8][\"images\"]\n","d9 = mnist_data_all[9][\"images\"]\n","\n","y2 = np.repeat(-1, len(d2)).reshape(1,-1)\n","y4 = np.repeat(1, len(d4)).reshape(1,-1)\n","\n","y6 = np.repeat(-1, len(d6)).reshape(1,-1)\n","y8 = np.repeat(1, len(d8)).reshape(1,-1)\n","\n","y9 = np.repeat(1, len(d9)).reshape(1,-1)\n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9ZQpmam_KHF8","colab_type":"code","colab":{}},"cell_type":"code","source":["def create_data_labels(d_0, d_1, y_0, y_1):\n","  # data goes into the feature computation functions\n","  data = np.vstack((d_0, d_1))\n","  # labels can directly go into the perceptron algorithm\n","  labels = np.vstack((y_0.T, y_1.T)).T\n","  return data, labels"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vsX_9X7Nb0NW","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","def raw_mnist_features(x):\n","    \"\"\"\n","    @param x (n_samples,m,n) array with values in (0,1)\n","    @return (m*n,n_samples) reshaped array where each entry is preserved\n","    \"\"\"\n","    # apply to the third dimension first\n","    n_samples, m, n = x.shape\n","    return np.reshape(x, (n_samples, m*n)).T\n","    \n","\n","def row_average_features(x):\n","    \"\"\"\n","    This should either use or modify your code from the tutor questions.\n","\n","    @param x (n_samples,m,n) array with values in (0,1)\n","    @return (m,n_samples) array where each entry is the average of a row\n","    \"\"\"\n","    # take the mean across columns\n","    return np.mean(x, axis=2,keepdims=False).T\n","\n","\n","def col_average_features(x):\n","    \"\"\"\n","    This should either use or modify your code from the tutor questions.\n","\n","    @param x (n_samples,m,n) array with values in (0,1)\n","    @return (n,n_samples) array where each entry is the average of a column\n","    \"\"\"\n","    # take the mean over rows\n","    return np.mean(x, axis=1,keepdims=False).T\n","\n","\n","def top_bottom_features(x):\n","    \"\"\"\n","    This should either use or modify your code from the tutor questions.\n","\n","    @param x (n_samples,m,n) array with values in (0,1)\n","    @return (2,n_samples) array where the first entry of each column is the average of the\n","    top half of the image = rows 0 to floor(m/2) [exclusive]\n","    and the second entry is the average of the bottom half of the image\n","    = rows floor(m/2) [inclusive] to m\n","    \"\"\"\n","    half = x.shape[1]//2\n","    top = np.mean(x[:, :half, :], axis=(1, 2), keepdims=False).reshape((1,-1))\n","    bottom = np.mean(x[:, half:, :], axis=(1, 2),  keepdims=False).reshape((1,-1))\n","    print(top.shape, bottom.shape)\n","    return np.concatenate((top, bottom), axis=0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZcEf5KA2BRk5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":225},"outputId":"6d68c39e-e478-4898-e1b3-928080a25a98","executionInfo":{"status":"ok","timestamp":1550891041113,"user_tz":300,"elapsed":3068,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["accs = []\n","for d_a, d_b, y_a, y_b in [(d0, d1, y0, y1),\n","                           (d2, d4, y2, y4), (d6, d8, y6, y8), \n","                           (d9, d0, y9, y0)]:\n","  data, labels = create_data_labels(d_a, d_b, y_a, y_b)\n","  print(data.shape)\n","  print(labels.shape)\n","  acc = hw3.get_classification_accuracy(raw_mnist_features(data), labels)\n","  print(acc)\n","  accs.append(acc)\n","  "],"execution_count":22,"outputs":[{"output_type":"stream","text":["(160, 28, 28)\n","(1, 160)\n","0.975\n","(155, 28, 28)\n","(1, 155)\n","0.8641666666666665\n","(154, 28, 28)\n","(1, 154)\n","0.9479166666666667\n","(155, 28, 28)\n","(1, 155)\n","0.6470833333333333\n"],"name":"stdout"}]},{"metadata":{"id":"fchSXNONLSiG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"216bd66c-0741-425c-ab90-ecbeacf2d3ed","executionInfo":{"status":"ok","timestamp":1550891047064,"user_tz":300,"elapsed":352,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["accs"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.975, 0.8641666666666665, 0.9479166666666667, 0.6470833333333333]"]},"metadata":{"tags":[]},"execution_count":23}]},{"metadata":{"id":"EYWKcT_8IYzV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"0c97c543-9c75-47fa-9232-dfd98f0bc0d1","executionInfo":{"status":"ok","timestamp":1550891509878,"user_tz":300,"elapsed":416,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["t = top_bottom_features(data)"],"execution_count":42,"outputs":[{"output_type":"stream","text":["(1, 160) (1, 160)\n"],"name":"stdout"}]},{"metadata":{"id":"jQvfauP9VY18","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"7662800b-266f-4bff-8dc9-7632c7fa6cad","executionInfo":{"status":"ok","timestamp":1550891511608,"user_tz":300,"elapsed":685,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["t.shape"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2, 160)"]},"metadata":{"tags":[]},"execution_count":43}]},{"metadata":{"id":"MKA__ZvzM26v","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":208},"outputId":"9e419a9e-360b-454d-bdb6-83bb3d4899c4","executionInfo":{"status":"ok","timestamp":1550891668213,"user_tz":300,"elapsed":2213,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["data, labels = create_data_labels(d9, d0, y9, y0)\n","accs= []\n","\n","for res_fnc in (row_average_features, col_average_features, top_bottom_features):\n","  processed = res_fnc(data)\n","  print(data.shape)\n","  print(processed.shape)\n","  accur = hw3.get_classification_accuracy(processed, labels)\n","  print(accur)\n","  accs.append(accur)\n","  \n","  \n","print(accs)"],"execution_count":49,"outputs":[{"output_type":"stream","text":["(155, 28, 28)\n","(28, 155)\n","0.49749999999999994\n","(155, 28, 28)\n","(28, 155)\n","0.5041666666666667\n","(1, 155) (1, 155)\n","(155, 28, 28)\n","(2, 155)\n","0.49749999999999994\n","[0.49749999999999994, 0.5041666666666667, 0.49749999999999994]\n"],"name":"stdout"}]},{"metadata":{"id":"J4pJLOw9VvER","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"6c77ebf4-90c8-43e5-fb1f-ab0062393f04","executionInfo":{"status":"ok","timestamp":1550891548859,"user_tz":300,"elapsed":399,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":[""],"execution_count":46,"outputs":[{"output_type":"stream","text":["[0.48125, 0.6375, 0.48125]\n"],"name":"stdout"}]},{"metadata":{"id":"9DTXfMoDgCKk","colab_type":"code","colab":{}},"cell_type":"code","source":["# use this function to evaluate accuracy\n","acc = hw3.get_classification_accuracy(raw_mnist_features(data), labels)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9c21c7bXCbNp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"6f555bb8-a1c0-4ea2-972a-c45047f92c26","executionInfo":{"status":"ok","timestamp":1550872278485,"user_tz":300,"elapsed":355,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["acc\n"],"execution_count":189,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4708333333333334"]},"metadata":{"tags":[]},"execution_count":189}]},{"metadata":{"id":"OR260yU6E4yM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"df8f6b38-8fec-4c4a-95e6-f8ad2f1eceab","executionInfo":{"status":"ok","timestamp":1550870387450,"user_tz":300,"elapsed":428,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["print(data.shape)"],"execution_count":108,"outputs":[{"output_type":"stream","text":["(160, 28, 28)\n"],"name":"stdout"}]},{"metadata":{"id":"K8oWHhcXE0L3","colab_type":"code","colab":{}},"cell_type":"code","source":["data_test = np.array([[[0, 1], [2, 3], [4, 5]]])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZLO4d70OG5q6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":86},"outputId":"679bbcda-66c3-46ca-b302-a3cc8efb3895","executionInfo":{"status":"ok","timestamp":1550870894463,"user_tz":300,"elapsed":399,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["print(data_test.shape)\n","data_test"],"execution_count":116,"outputs":[{"output_type":"stream","text":["(1, 3, 2)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array([[[0, 1],\n","        [2, 3],\n","        [4, 5]]])"]},"metadata":{"tags":[]},"execution_count":116}]},{"metadata":{"id":"1Et_hfN4G5wq","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"-vUAJAgiGvkZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"54edf871-865c-4e26-f33d-33813c217578","executionInfo":{"status":"ok","timestamp":1550870990401,"user_tz":300,"elapsed":408,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["np.mean(data_test, axis=2)"],"execution_count":118,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.5, 2.5, 4.5]])"]},"metadata":{"tags":[]},"execution_count":118}]},{"metadata":{"id":"aMRi-4DuCJaw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"2afcd66b-0ddf-4365-c222-927973b99616","executionInfo":{"status":"ok","timestamp":1550870323353,"user_tz":300,"elapsed":349,"user":{"displayName":"Lindsey Raymond","photoUrl":"","userId":"12017110552411429068"}}},"cell_type":"code","source":["np.mean(data_flat, axis=1,keepdims=True).shape"],"execution_count":106,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(160, 1, 1)"]},"metadata":{"tags":[]},"execution_count":106}]}]}